---
title: "Predicciones de Series de Tiempo en R"
subtitle: "Visualización Científica"
description: |
  Un proceso estocástico es una colección o familia de variables aleatorias $\{X_{t}\}_{t\in I}$ ordenadas según el subíndice $t$ que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si $I$ es discreto, el proceso es en tiempo discreto. Si $I$ es continuo, el proceso es en tiempo continuo.
---

## 1. punto

Considere la serie de tiempo asociada con las acciones de Tecnoglass desde que comenzó a comercializarse hasta la fecha del día de hoy. Puede utilizar la API de Yahoo Finance para obtener esta serie de tiempo (ver yahoofinancer).

Iniciamos el análisis cargando los paquetes necesarios en R

```{r, output = FALSE}


library(yfR)
library(quantmod)
library(plotly)
library(dplyr)
library(tseries)
library(TSstudio)
library(forecast)
library(quantmod) 
library(ggplot2)
library(gridExtra) 


```

Se define el intervalo de tiempo para el análisis y cargas los datos históricos de las acciones de Tecnoglass

```{r, output = FALSE}


fec_ini <- "2012-05-10"  
fec_fin <- Sys.Date()  

simb <- "TGLS"

datos_tgls <- yf_get(
  tickers = simb,
  first_date = fec_ini,
  last_date = fec_fin
)


```

```{r}
knitr::kable(head(datos_tgls))

```

### Exploración de Datos:

```{r}

plot_ly(data = datos_tgls, type = "candlestick",
        x = ~ref_date,
        open = ~price_open,
        close = ~price_close,
        high = ~price_high,
        low = ~price_low,
        name = "Candlesticks") %>%
  layout(title = "Candlestick de Tecnoglass",
         xaxis = list(title = "Fecha"),
         yaxis = list(title = "Precio"))

```

El gráfico de velas muestra una tendencia general alcista, especialmente hacia las fechas mas recietes donde se observa un aumento significativo en los precios. Este patrón general sugiere que la acción ha tenido una buena recepción en el mercado, atrayendo un interés creciente de los inversores.

Convertimos los datos de precios de cierre de Tecnoglass en una serie temporal para facilitar análisis posteriores y se define la frecuencia a 250 días hábiles por año.

```{r}
frecuencia <- 250  

tgls_ts <- ts(datos_tgls$price_close, 
              frequency = frecuencia, 
              start = c(as.integer(format(min(datos_tgls$ref_date), "%Y")),
                        as.integer(format(min(datos_tgls$ref_date), "%j"))))

```

Comprobamos si hay valores faltantes en la serie temporal

```{r}
sum(is.na(tgls_ts))
```

No hay datos faltantes en la serie, lo que significa que podemos proceder con el análisis

```{r}

ts_plot(tgls_ts,
        title = "Precios de Cierre de Tecnoglass 2013-Presente",
        Ytitle = "Precio de cierre",
        Xtitle = "Año")

```

El gráfico muestra una tendencia alcista significativa desde 2020, con una volatilidad creciente en los precios de cierre. No se aprecian patrones estacionales claros, pero sí una mayor fluctuación de precios en los últimos años, sugiriendo cambios potenciales en la dinámica del mercado o en la empresa.

```{r}
ts_decompose(tgls_ts)
```

La descomposición muestra una tendencia claramente alcista, que domina sobre la estacionalidad y el componente aleatorio. La falta de una estacionalidad marcada sugiere que las decisiones de inversión y los eventos del mercado relacionados con estas acciones podrían estar más influenciados por factores específicos de la empresa o eventos del mercado más amplios en lugar de patrones estacionales.

```{r}
summary(tgls_ts)
```

En promedio, las acciones se cotizaron a \$15.09, con una mediana más baja de \$10.50, indicando una distribución de precios con tendencia hacia valores más bajos, pero con picos que alcanzan hasta los \$59.00

```{r}
# Histograma de los precios de cierre
hist(tgls_ts, 
     main = "Histograma de Precios de Cierre de Tecnoglass", 
     xlab = "Precio de cierre", 
     breaks = "Sturges", 
     probability = TRUE, 
     col = "lightblue")

lines(density(tgls_ts), col = "darkblue", lwd = 2)
```

El histograma revela que los precios de cierre de Tecnoglass habian permanecidos principalmente en un rango bajo, con recientes picos con valores más altos.

### Prueba de Estacionariedad

Mas alla de lo visual podemos apelar a pruebas de hipotesis para saber si la serie de tiempo es estacionaria, a traves del Test de Dickey-Fuller Aumentado.

```{r}

adf.test(tgls_ts, alternative = "stationary")
```

la prueba sugiere que la serie temporal de los precios de cierre de Tecnoglass no es estacionaria y puede contener una tendencia o una estructura dependiente del tiempo que no ha sido eliminada

### Preparación y Diagnóstico de la Serie Temporal

Para evaluar la efectividad de los modelos predictivos, dividimos la serie temporal de precios de cierre en dos partes: un conjunto de entrenamiento y un conjunto de prueba. El conjunto de prueba consiste en los últimos 28 días, que reservamos para evaluar el modelo, mientras que el resto de los datos se utiliza para entrenarlo.

```{r}

tgls_split <- ts_split(tgls_ts, sample.out = 28)

train <- tgls_split$train
test <- tgls_split$test

```

Para ayudar en la selección de los parámetros del modelo ARIMA, graficamos las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para el conjunto de entrenamiento

```{r}
par(mfrow = c(1, 2))
acf(train, lag.max = 250)
pacf(train, lag.max = 250)
```

El gráfico ACF muestra una disminución gradual de las autocorrelaciones que no cortan rápidamente hacia cero, lo que podría sugerir un proceso AR (autorregresivo) o la presencia de una raíz unitaria, indicando que la serie podría no ser estacionaria.

### Diferenciación para Estacionalidad

Ahora procedemos a diferenciar la serie de tiempo de entrenamiento para eliminar cualquier tendencia o estacionalidad y estabilizar la media.

```{r}
tgls_d <- diff(train, 1)

ts_plot(tgls_d,
        title = "Tecnoglass - Diferenciación Estacional",
        Ytitle = "Diferencia de Precios",
        Xtitle = "Año")


```

Corroboramos estacionaridad con el Test de Dickey-Fuller Aumentado con: 

$\mathit{H_0}$ : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición no es estacionaria.

$\mathit{H_1}$ : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición es estacionaria.

```{r}

adf.test(tgls_d, alternative = "stationary")
```
Con un p-valor=0.01 rechazamos la hipotesis nula de no estacionariedad.
Después de tomar la diferenciación de primer orden, junto con la diferenciación estacional de primer orden, la serie parece estabilizarse en torno a la línea del eje x cero (o bastante cerca de ser estable). Después de transformar la serie en un estado estacionario, podemos revisar las funciones ACF y PACF de nuevo para identificar el proceso necesario

```{r}
par(mfrow=c(1,2))
acf(tgls_d, lag.max = 250)
pacf(tgls_d, lag.max = 250)
```

En el gráfico ACF a la izquierda, las correlaciones en los primeros retrasos son bajas y parecen caer dentro del área de confianza, lo que indica que la diferenciación ha ayudado a remover cualquier autocorrelación.El gráfico PACF a la derecha muestra una cantidad significativa de picos fuera del área de confianza, lo que puede indicar que un modelo ARIMA con términos de media móvil podría ser apropiado.

## punto 2

Repita TODOS los pasos indicados en esta sección para encontrar modelos ARIMA para predecir el precio de las acciones de Tecnoglass con los siguientes horizontes: 7, 14 días, 21 días, 28 días. Utilizar siempre predicciones usando rolling con ventana de predicción continua de un día. Cualquier cantidad de pasos extra para enriquecer su análisis predictivo serán aceptados siempre y cuando sean acordes con lo que indica la teoría de análisis de series de tiempo.

Inicialmente aplicamos la función auto.arima para seleccionar de forma automática el mejor modelo ARIMA para nuestros datos de entrenamiento. Este enfoque nos permite identificar el modelo que mejor se ajusta a la serie temporal sin la neces

### Auto-arima

```{r}
# Ajuste del modelo ARIMA usando auto.arima
if (!file.exists("auto_arima.rda")) {
  tgls_auto_model <- auto.arima(train,
                             max.order = 3,
                             D = 1,
                             d = 1,
                             stepwise = FALSE,
                             approximation = FALSE)
  saveRDS(tgls_auto_model, "auto_arima.rda")
} else {
  tgls_auto_model <- readRDS("auto_arima.rda")
}

# Muestra el modelo
print(tgls_auto_model)

```

Los resultados del auto.arima nos han proporcionado un modelo ARIMA(3,1,0)(0,1,0)\[250\] para nuestra serie temporal de precios de cierre de Tecnoglass, lo que sugiere que la mejor manera de entender y predecir estos datos es a través de la relación de los precios con sus tres valores anteriores y una tendencia estabilizada por diferenciación.

```{r}
checkresiduals(tgls_auto_model)
```

los diagnósticos de residuos del modelo ARIMA muestra que los residuos no exhiben patrones claros a lo largo del tiempo, lo cual es una buena señal de que el modelo se ajusta adecuadamente a los datos. La ACF de los residuos no muestra autocorrelaciones significativas, lo que sugiere que el modelo ha capturado bien la dinámica de la serie temporal. Además, la distribución de los residuos parece aproximadamente normal \### ARIMA con base en la minimización del coeficiente de Akaike (AIC) La función best_ARIMA prueba modelos con diferentes números de términos autoregresivos (p), de diferenciación (d), y de media móvil (q), incluyendo también sus equivalentes estacionales (P, D, Q).

```{r}
best_ARIMA <- function(ts_in, p_n, d_n, q_n) {
  best_aic <- Inf
  best_pdq <- NULL
  best_PDQ <- NULL
  fit <- NULL
  for(p in 1:p_n) {
    for(d in 1:d_n) {
      for (q in 1:q_n) {
        for(P in 1:p_n) {
          for(D in 1:d_n) {
            for (Q in 1:q_n) {
              tryCatch({
                fit <- arima(scale(ts_in), 
                             order=c(p, d, q), 
                             seasonal = list(order = c(P, D, Q), period = 250),
                             xreg=1:length(ts_in), 
                             method="CSS-ML")
                tmp_aic <- AIC(fit)
                if (tmp_aic < best_aic) {
                  best_aic <- tmp_aic
                  best_pdq = c(p, d, q)
                  best_PDQ = c(P, D, Q)
                }
              }, error=function(e){})
            }
          }
        }
      }
    }
  }
  return(list("best_aic" = best_aic, "best_pdq" = best_pdq, "best_PDQ" = best_PDQ))
}
```

```{r}
if(file.exists("best_arima.rda")) {
  best_model = readRDS("best_arima.rda")
} else {
  best_model = best_ARIMA(train, 3, 1, 3)
  saveRDS(best_model, file = "best_arima.rda")
}
```

```{r}
print(best_model)
```

```{r}
fit_model <- NULL
if(file.exists("TGLS_model.rda")) {
fit_model = readRDS("TGLS_model.rda")
} else {
  fit_model <- arima(train, order = c(3,1,3), 
                  seasonal = list(order = c(1,1,1)))
  
  saveRDS(fit_model, file = "TGLS_model.rda")
}
```

```{r}
fit_model
```

Los coeficientes estimados para los términos autoregresivos y de media móvil son estadísticamente significativos, con el tercer término AR y el tercer término MA destacándose por su magnitud. Esto sugiere una fuerte relación entre los precios actuales y los precios pasados, tanto en la tendencia general como en la estacionalidad anual.

```{r}
checkresiduals(fit_model) 
```

los residuos no exhiben patrones claros a lo largo del tiempo, lo cual es una buena señal de que el modelo se ajusta adecuadamente a los datos. La ACF de los residuos no muestra autocorrelaciones significativas, lo que sugiere que el modelo ha capturado bien la dinámica de la serie temporal. Además, la distribución de los residuos parece aproximadamente normal

Como el AIC del filt_model es menor que el generado con la funcion autoarima, procedemos a realizar las predicciones con el fitl_model.

### Modelado ARIMA con Rolling Forecast:

generamos la función pred_rolling, la cual es clave para simular un escenario realista de pronóstico donde el modelo ARIMA se actualiza continuamente con nuevos datos. Esta función adopta el enfoque de Rolling Forecast, reajustando el modelo de forma secuencial para cada punto de dato en el conjunto de prueba y utilizando la información más reciente disponible.

```{r}

pred_rolling <- function(historico, prueba, modelo) {
  predicciones <- numeric(length(prueba))
  
  for (t in seq_along(prueba)) {
    modelo_ajustado <- Arima(historico, model=modelo)
    pronostico <- forecast(modelo_ajustado, h=1)
    predicciones[t] <- pronostico$mean
    historico <- c(historico, prueba[t])
  }
  return(predicciones)
}

```

A traves de este código automatiza la evaluación y visualizacion del modelo ARIMA sobre diferentes horizontes temporales (7, 14, 21 y 28 días) para verificar su eficacia predictiva en condiciones variadas.

```{r}
horizontes <- c(7, 14, 21, 28)
results_rolling <- list()

for(h in horizontes) {
  
  datos_split <- ts_split(tgls_ts, sample.out = h)
  train <- datos_split$train
  test <- datos_split$test
  
  # Archivo donde se guardarán las predicciones
  archivo_pred <- paste0("pred_", h, "d_roll.rda")
  
  if(!file.exists(archivo_pred)) {
    pred_roll <- pred_rolling(train, test, fit_model)
    saveRDS(pred_roll, archivo_pred)
  } else {
    pred_roll <- readRDS(archivo_pred)
  }
  
  
  # Crear DataFrames para la visualización
  df_entrenamiento <- data.frame(Fecha = time(train), Valor = as.numeric(train))
  df_prueba <- data.frame(Fecha = time(test), Valor = as.numeric(test))
  df_predicciones <- data.frame(Fecha = time(test), Valor = pred_roll)
  
  plot_name <- paste0("plot_rolling_", h)
  
  # Visualización de los resultados con Plotly
  p <- plot_ly() %>%
    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = "Entrenamiento", line = list(color = '#000D61')) %>%
    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = "Prueba", line = list(color = '#00C5DF')) %>%
    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = "Predicción", line = list(color = '#DF6401')) %>%
    layout(title = paste("Predicción ARIMA Rolling -", h, "días"),
           xaxis = list(title = "Fecha"),
           yaxis = list(title = "Precio"),
           showlegend = TRUE)
  
  assign(plot_name, p)
  
  
  metrics <- forecast::accuracy(pred_roll, test)
  results_rolling[[paste("Horizon", h, "days")]] <- metrics
  
}




```

# punto 3

Repita el paso 2 ahora sin utilizar rolling. Esto es, realice el pronóstico solo utilizando forecast() para los diferentes horizontes de predicción, 7, 14 días, 21 días, 28 días.

Nos valemos de un enfoque sistemático para evaluar la efectividad del modelo ARIMA en pronosticar el precio de las acciones en diferentes horizontes temporales (7, 14, 21 y 28 días).

```{r}

horizontes <- c(7, 14, 21, 28)
results_forecast <- list()


for (h in horizontes) {
  archivo_pred <- paste0("pred_", h, "d.rda")
  
  if(!file.exists(archivo_pred)) {
    pred <- forecast(fit_model, h = h)
    saveRDS(pred, archivo_pred)
  } else {
    pred <- readRDS(archivo_pred)
  }
  
  plot_name <- paste0("plot_forecast_", h)

  p<-plot_forecast(pred,
                title = paste("Predicción ARIMA - ", h, " días"),
                Ytitle = "Precio",
                Xtitle = "Fecha")
  
  assign(plot_name, p)
  
  metrics <- forecast::accuracy(pred$mean, test)
  results_forecast[[paste("Horizon", h, "days")]] <- metrics
}


```

```{r}
pred_28 <- forecast(fit_model, h = 28)


 
print(test_forecast(tgls_ts,
              forecast.obj = pred_28,
              test = test))
  
```

Para visualizar y comparar de forma efectiva las predicciones de cada horizonte y por cada método de predicción, podemos crear una serie de gráficos que nos permitan observar las diferencias y similitudes en las estimaciones que cada método proporciona.

### Predicciones para  7 dias

```{r}
plot_rolling_7 <- plot_rolling_7 %>% layout(title = "Rolling Forecast", titleposition = "bottom center")
plot_forecast_7 <- plot_forecast_7 %>% layout(title = "Direct Forecast", titleposition = "bottom center")

combined_plot <- subplot(plot_rolling_7, plot_forecast_7, 
                         nrows = 1, 
                         margin = 0.05) 

combined_plot <- combined_plot %>% layout(title = "Rolling Forecast vs Direct Forecast")

combined_plot
```

### Predicciones para  14 dias

```{r}
plot_rolling_14 <- plot_rolling_14 %>% layout(title = "Rolling Forecast", titleposition = "bottom center")
plot_forecast_14 <- plot_forecast_7 %>% layout(title = "Direct Forecast", titleposition = "bottom center")

combined_plot <- subplot(plot_rolling_14, plot_forecast_14, 
                         nrows = 1, 
                         margin = 0.05) 

combined_plot <- combined_plot %>% layout(title = "Rolling Forecast vs Direct Forecast")

combined_plot
```
### Predicciones para  21 dias

```{r}
plot_rolling_21 <- plot_rolling_21 %>% layout(title = "Rolling Forecast", titleposition = "bottom center")
plot_forecast_21 <- plot_forecast_21 %>% layout(title = "Direct Forecast", titleposition = "bottom center")

combined_plot <- subplot(plot_rolling_21, plot_forecast_21, 
                         nrows = 1, 
                         margin = 0.05) 

combined_plot <- combined_plot %>% layout(title = "Rolling Forecast vs Direct Forecast")

combined_plot
```
### Predicciones para  28 dias

```{r}
plot_rolling_28 <- plot_rolling_28 %>% layout(title = "Rolling Forecast", titleposition = "bottom center")
plot_forecast_28 <- plot_forecast_28 %>% layout(title = "Direct Forecast", titleposition = "bottom center")

combined_plot <- subplot(plot_rolling_28, plot_forecast_28, 
                         nrows = 1, 
                         margin = 0.05) 

combined_plot <- combined_plot %>% layout(title = "Rolling Forecast vs Direct Forecast")

combined_plot
```
Al comparar los métodos de predicción a través de distintos horizontes temporales, se observa que las predicciones son relativamente similares para horizontes cortos. Sin embargo, a medida que se extiende el horizonte de predicción, las diferencias entre los métodos se hacen más pronunciadas. Específicamente, para horizontes más largos, el método de Rolling Forecast muestra una tendencia más acertada y alineada con los valores reales. Esto puede indicar que el método Rolling Forecast es más eficaz para capturar y ajustar a las dinámicas cambiantes de los datos a lo largo del tiempo, lo cual es crucial para realizar proyecciones a largo plazo con mayor precisión.


# punto 4

### Metricas para 7 dias
```{r}
results_rolling[["Horizon 7 days"]]
results_forecast[["Horizon 7 days"]]
```
### Metricas para 14 dias
```{r}
results_rolling[["Horizon 14 days"]]
results_forecast[["Horizon 14 days"]]
```
### Metricas para 21 dias
```{r}
results_rolling[["Horizon 21 days"]]
results_forecast[["Horizon 21 days"]]
```

### Metricas para 28 dias
```{r}
results_rolling[["Horizon 28 days"]]
results_forecast[["Horizon 28 days"]]
```
El método Rolling Forecast se demuestra superior en este análisis por sus errores consistentemente más bajos y su robustez en distintos horizontes temporales. Esto sugiere que la actualización continua del modelo y la utilización de información más reciente al hacer las predicciones son ventajas claras de este enfoque, haciéndolo más adecuado para aplicaciones prácticas donde la precisión y la fiabilidad son críticas.

## Gráfico de correlación entre la observación real y su predicción 
Para evaluar y comparar la efectividad de las técnicas de predicción Rolling Forecast y Direct Forecast, analizamos la correlación entre las predicciones de cada técnica y los valores reales observados.

```{r}

create_correlation_plot <- function(actual, predicted, title) {
  data <- data.frame(Actual = actual, Predicted = predicted)
  ggplot(data, aes(x = Actual, y = Predicted)) +
    geom_point(color = 'blue', alpha = 0.5) +
    geom_smooth(method = "lm", se = FALSE, color = "red") +
    ggtitle(paste(title, "\nR^2:", round(summary(lm(Predicted ~ Actual, data = data))$r.squared, 3))) +
    xlab("Valores Reales") +
    ylab("Valores Predichos") +
    theme_minimal()
}

plot_rolling <- create_correlation_plot(test, pred_roll, "Correlación Rolling Forecast")

plot_forecast <- create_correlation_plot(test, pred$mean, "Correlación Direct Forecast")

grid.arrange(plot_rolling, plot_forecast, ncol = 2)
```

El método Rolling Forecast demuestra ser considerablemente más confiable y preciso,  para este conjunto de datos, lo que sugiere que es el enfoque preferible para las predicciones a futuro basadas en esta serie temporal.

# Criterio BIC y HQIC

## Cirterio BIC

``` {r}
best_ARIMA_BIC <- function(ts_in, p_n, d_n, q_n) {
  best_bic <- Inf
  best_pdq <- NULL
  best_PDQ <- NULL
  fit <- NULL
  for(p in 1:p_n) {
    for(d in 1:d_n) {
      for (q in 1:q_n) {
        for(P in 1:p_n) {
          for(D in 1:d_n) {
            for (Q in 1:q_n) {
              tryCatch({
                fit <- arima(scale(ts_in), 
                             order=c(p, d, q), 
                             seasonal = list(order = c(P, D, Q), period = 250),
                             xreg=1:length(ts_in), 
                             method="CSS-ML")
                tmp_bic <- BIC(fit)
                if (tmp_bic < best_bic) {
                  best_bic <- tmp_bic
                  best_pdq <- c(p, d, q)
                  best_PDQ <- c(P, D, Q)
                }
              }, error=function(e){})
            }
          }
        }
      }
    }
  }
  return(list("best_bic" = best_bic, "best_pdq" = best_pdq, "best_PDQ" = best_PDQ))
}
```

``` {r}
best_model_bic <- NULL
if(file.exists("best_arima_bic.rda")) {
  best_model_bic = readRDS("best_arima_bic.rda")
} else {
  best_model_bic = best_ARIMA_BIC(train, 3, 1, 3)
  saveRDS(best_model_bic, file = "best_arima_bic.rda")
}

best_model_bic 
```

## Criterio HQIC

``` {r}
best_ARIMA_HQIC <- function(ts_in, p_n, d_n, q_n) {
  best_hqic <- Inf
  best_pdq <- NULL
  best_PDQ <- NULL
  fit <- NULL
  for(p in 1:p_n) {
    for(d in 1:d_n) {
      for (q in 1:q_n) {
        for(P in 1:p_n) {
          for(D in 1:d_n) {
            for (Q in 1:q_n) {
              tryCatch({
                fit <- arima(scale(ts_in), 
                             order=c(p, d, q), 
                             seasonal = list(order = c(P, D, Q), period = 250),
                             xreg=1:length(ts_in), 
                             method="CSS-ML")
                tmp_hqic <- AIC(fit, k = log(length(ts_in)))
                if (tmp_hqic < best_hqic) {
                  best_hqic <- tmp_hqic
                  best_pdq <- c(p, d, q)
                  best_PDQ <- c(P, D, Q)
                }
              }, error=function(e){})
            }
          }
        }
      }
    }
  }
  return(list("best_hqic" = best_hqic, "best_pdq" = best_pdq, "best_PDQ" = best_PDQ))
}
```

``` {r}
best_model_hqic <- NULL
if(file.exists("best_arima_hqic.rda")) {
  best_model_hqic = readRDS("best_arima_hqic.rda")
} else {
  best_model_hqic = best_ARIMA_HQIC(train, 4, 1, 4)
  saveRDS(best_model_hqic, file = "best_arima_hqic.rda")
}

best_model_hqic
```

Como podemos notar, los resultados obtenidos para los modelos generados bajo los criterios de `BIC` y `HQIC` son iguales al obtenido mediante el criterio de `AIC`. Por tanto, los análisis que hiciesemos similares a los del `AIC` serán los mismos.

# Conclusión

Los resultados obtenidos mediante la técnica de `rolling forecasting` junto con los criterios de **Akaike** (`AIC`), **inferencia Bayesiana** (`BIC`) y **información de Hannan-Quinn** (`HQIC`) mostraron una mejora en el rendimiento del modelo en comparación con los modelos obtenidos sin aplicar esta técnica. Sin embargo, a pesar de esta mejora, los modelos aún no lograron ofrecer predicciones precisas. Las métricas evaluadas, como el coeficiente de determinación (`R2`), indican que el ajuste del modelo a los datos de la serie de tiempo sigue siendo insuficiente. Además, las pruebas de normalidad de los residuos revelan que estos no siguen una distribución normal, lo que sugiere que los modelos no cumplen con los supuestos necesarios para realizar predicciones confiables.

Ante esta situación, se hace necesario explorar otros modelos estadísticos para series de tiempo. Se pueden considerar modelos más avanzados, como los modelos de **aprendizaje automático**, que pueden capturar mejor la complejidad de la serie temporal y ofrecer predicciones más precisas. En resumen, es crucial continuar explorando y experimentando con diferentes enfoques para encontrar el modelo que mejor se ajuste a los datos y produzca predicciones confiables.


