[
  {
    "objectID": "ts_r.html",
    "href": "ts_r.html",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "",
    "text": "Considere la serie de tiempo asociada con las acciones de Tecnoglass desde que comenzó a comercializarse hasta la fecha del día de hoy. Puede utilizar la API de Yahoo Finance para obtener esta serie de tiempo (ver yahoofinancer).\nIniciamos el análisis cargando los paquetes necesarios en R\n\nlibrary(yfR)\nlibrary(quantmod)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(tseries)\nlibrary(TSstudio)\nlibrary(forecast)\nlibrary(quantmod) \nlibrary(ggplot2)\nlibrary(gridExtra) \n\nSe define el intervalo de tiempo para el análisis y cargas los datos históricos de las acciones de Tecnoglass\n\nfec_ini &lt;- \"2012-05-10\"  \nfec_fin &lt;- Sys.Date()  \n\nsimb &lt;- \"TGLS\"\n\ndatos_tgls &lt;- yf_get(\n  tickers = simb,\n  first_date = fec_ini,\n  last_date = fec_fin\n)\n\n\nknitr::kable(head(datos_tgls))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nticker\nref_date\nprice_open\nprice_high\nprice_low\nprice_close\nvolume\nprice_adjusted\nret_adjusted_prices\nret_closing_prices\ncumret_adjusted_prices\n\n\n\n\nTGLS\n2012-05-10\n9.97\n10.00\n9.50\n9.80\n6900\n7.708228\nNA\nNA\n1.0000000\n\n\nTGLS\n2012-05-11\n9.70\n9.70\n9.70\n9.70\n300\n7.629572\n-0.0102042\n-0.0102041\n0.9897958\n\n\nTGLS\n2012-05-14\n9.80\n9.80\n9.80\n9.80\n100\n7.708228\n0.0103094\n0.0103093\n1.0000000\n\n\nTGLS\n2012-05-15\n9.75\n9.75\n9.75\n9.75\n300\n7.668901\n-0.0051020\n-0.0051021\n0.9948980\n\n\nTGLS\n2012-05-16\n9.75\n9.75\n9.75\n9.75\n0\n7.668901\n0.0000000\n0.0000000\n0.9948980\n\n\nTGLS\n2012-05-17\n9.60\n9.60\n9.60\n9.60\n800\n7.550920\n-0.0153843\n-0.0153846\n0.9795922\n\n\n\n\n\n\n\n\nplot_ly(data = datos_tgls, type = \"candlestick\",\n        x = ~ref_date,\n        open = ~price_open,\n        close = ~price_close,\n        high = ~price_high,\n        low = ~price_low,\n        name = \"Candlesticks\") %&gt;%\n  layout(title = \"Candlestick de Tecnoglass\",\n         xaxis = list(title = \"Fecha\"),\n         yaxis = list(title = \"Precio\"))\n\n\n\n\n\nEl gráfico de velas muestra una tendencia general alcista, especialmente hacia las fechas mas recietes donde se observa un aumento significativo en los precios. Este patrón general sugiere que la acción ha tenido una buena recepción en el mercado, atrayendo un interés creciente de los inversores.\nConvertimos los datos de precios de cierre de Tecnoglass en una serie temporal para facilitar análisis posteriores y se define la frecuencia a 250 días hábiles por año.\n\nfrecuencia &lt;- 250  \n\ntgls_ts &lt;- ts(datos_tgls$price_close, \n              frequency = frecuencia, \n              start = c(as.integer(format(min(datos_tgls$ref_date), \"%Y\")),\n                        as.integer(format(min(datos_tgls$ref_date), \"%j\"))))\n\nComprobamos si hay valores faltantes en la serie temporal\n\nsum(is.na(tgls_ts))\n\n[1] 0\n\n\nNo hay datos faltantes en la serie, lo que significa que podemos proceder con el análisis\n\nts_plot(tgls_ts,\n        title = \"Precios de Cierre de Tecnoglass 2013-Presente\",\n        Ytitle = \"Precio de cierre\",\n        Xtitle = \"Año\")\n\n\n\n\n\nEl gráfico muestra una tendencia alcista significativa desde 2020, con una volatilidad creciente en los precios de cierre. No se aprecian patrones estacionales claros, pero sí una mayor fluctuación de precios en los últimos años, sugiriendo cambios potenciales en la dinámica del mercado o en la empresa.\n\nts_decompose(tgls_ts)\n\n\n\n\n\nLa descomposición muestra una tendencia claramente alcista, que domina sobre la estacionalidad y el componente aleatorio. La falta de una estacionalidad marcada sugiere que las decisiones de inversión y los eventos del mercado relacionados con estas acciones podrían estar más influenciados por factores específicos de la empresa o eventos del mercado más amplios en lugar de patrones estacionales.\n\nsummary(tgls_ts)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.29    8.85   10.18   14.81   14.92   59.00 \n\n\nEn promedio, las acciones se cotizaron a $15.09, con una mediana más baja de $10.50, indicando una distribución de precios con tendencia hacia valores más bajos, pero con picos que alcanzan hasta los $59.00\n\n# Histograma de los precios de cierre\nhist(tgls_ts, \n     main = \"Histograma de Precios de Cierre de Tecnoglass\", \n     xlab = \"Precio de cierre\", \n     breaks = \"Sturges\", \n     probability = TRUE, \n     col = \"lightblue\")\n\nlines(density(tgls_ts), col = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\nEl histograma revela que los precios de cierre de Tecnoglass habian permanecidos principalmente en un rango bajo, con recientes picos con valores más altos.\n\n\n\nMas alla de lo visual podemos apelar a pruebas de hipotesis para saber si la serie de tiempo es estacionaria, a traves del Test de Dickey-Fuller Aumentado.\n\nadf.test(tgls_ts, alternative = \"stationary\")\n\nWarning in adf.test(tgls_ts, alternative = \"stationary\"): p-value greater than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tgls_ts\nDickey-Fuller = -0.27629, Lag order = 14, p-value = 0.99\nalternative hypothesis: stationary\n\n\nla prueba sugiere que la serie temporal de los precios de cierre de Tecnoglass no es estacionaria y puede contener una tendencia o una estructura dependiente del tiempo que no ha sido eliminada\n\n\n\nPara evaluar la efectividad de los modelos predictivos, dividimos la serie temporal de precios de cierre en dos partes: un conjunto de entrenamiento y un conjunto de prueba. El conjunto de prueba consiste en los últimos 28 días, que reservamos para evaluar el modelo, mientras que el resto de los datos se utiliza para entrenarlo.\n\ntgls_split &lt;- ts_split(tgls_ts, sample.out = 28)\n\ntrain &lt;- tgls_split$train\ntest &lt;- tgls_split$test\n\nPara ayudar en la selección de los parámetros del modelo ARIMA, graficamos las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para el conjunto de entrenamiento\n\npar(mfrow = c(1, 2))\nacf(train, lag.max = 250)\npacf(train, lag.max = 250)\n\n\n\n\n\n\n\n\nEl gráfico ACF muestra una disminución gradual de las autocorrelaciones que no cortan rápidamente hacia cero, lo que podría sugerir un proceso AR (autorregresivo) o la presencia de una raíz unitaria, indicando que la serie podría no ser estacionaria.\n\n\n\nAhora procedemos a diferenciar la serie de tiempo de entrenamiento para eliminar cualquier tendencia o estacionalidad y estabilizar la media.\n\ntgls_d &lt;- diff(train, 1)\n\nts_plot(tgls_d,\n        title = \"Tecnoglass - Diferenciación Estacional\",\n        Ytitle = \"Diferencia de Precios\",\n        Xtitle = \"Año\")\n\n\n\n\n\nCorroboramos estacionaridad con el Test de Dickey-Fuller Aumentado con:\n\\(\\mathit{H_0}\\) : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición no es estacionaria.\n\\(\\mathit{H_1}\\) : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición es estacionaria.\n\nadf.test(tgls_d, alternative = \"stationary\")\n\nWarning in adf.test(tgls_d, alternative = \"stationary\"): p-value smaller than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tgls_d\nDickey-Fuller = -13.579, Lag order = 14, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCon un p-valor=0.01 rechazamos la hipotesis nula de no estacionariedad. Después de tomar la diferenciación de primer orden, junto con la diferenciación estacional de primer orden, la serie parece estabilizarse en torno a la línea del eje x cero (o bastante cerca de ser estable). Después de transformar la serie en un estado estacionario, podemos revisar las funciones ACF y PACF de nuevo para identificar el proceso necesario\n\npar(mfrow=c(1,2))\nacf(tgls_d, lag.max = 250)\npacf(tgls_d, lag.max = 250)\n\n\n\n\n\n\n\n\nEn el gráfico ACF a la izquierda, las correlaciones en los primeros retrasos son bajas y parecen caer dentro del área de confianza, lo que indica que la diferenciación ha ayudado a remover cualquier autocorrelación.El gráfico PACF a la derecha muestra una cantidad significativa de picos fuera del área de confianza, lo que puede indicar que un modelo ARIMA con términos de media móvil podría ser apropiado.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "ts_r.html#punto",
    "href": "ts_r.html#punto",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "",
    "text": "Considere la serie de tiempo asociada con las acciones de Tecnoglass desde que comenzó a comercializarse hasta la fecha del día de hoy. Puede utilizar la API de Yahoo Finance para obtener esta serie de tiempo (ver yahoofinancer).\nIniciamos el análisis cargando los paquetes necesarios en R\n\nlibrary(yfR)\nlibrary(quantmod)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(tseries)\nlibrary(TSstudio)\nlibrary(forecast)\nlibrary(quantmod) \nlibrary(ggplot2)\nlibrary(gridExtra) \n\nSe define el intervalo de tiempo para el análisis y cargas los datos históricos de las acciones de Tecnoglass\n\nfec_ini &lt;- \"2012-05-10\"  \nfec_fin &lt;- Sys.Date()  \n\nsimb &lt;- \"TGLS\"\n\ndatos_tgls &lt;- yf_get(\n  tickers = simb,\n  first_date = fec_ini,\n  last_date = fec_fin\n)\n\n\nknitr::kable(head(datos_tgls))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nticker\nref_date\nprice_open\nprice_high\nprice_low\nprice_close\nvolume\nprice_adjusted\nret_adjusted_prices\nret_closing_prices\ncumret_adjusted_prices\n\n\n\n\nTGLS\n2012-05-10\n9.97\n10.00\n9.50\n9.80\n6900\n7.708228\nNA\nNA\n1.0000000\n\n\nTGLS\n2012-05-11\n9.70\n9.70\n9.70\n9.70\n300\n7.629572\n-0.0102042\n-0.0102041\n0.9897958\n\n\nTGLS\n2012-05-14\n9.80\n9.80\n9.80\n9.80\n100\n7.708228\n0.0103094\n0.0103093\n1.0000000\n\n\nTGLS\n2012-05-15\n9.75\n9.75\n9.75\n9.75\n300\n7.668901\n-0.0051020\n-0.0051021\n0.9948980\n\n\nTGLS\n2012-05-16\n9.75\n9.75\n9.75\n9.75\n0\n7.668901\n0.0000000\n0.0000000\n0.9948980\n\n\nTGLS\n2012-05-17\n9.60\n9.60\n9.60\n9.60\n800\n7.550920\n-0.0153843\n-0.0153846\n0.9795922\n\n\n\n\n\n\n\n\nplot_ly(data = datos_tgls, type = \"candlestick\",\n        x = ~ref_date,\n        open = ~price_open,\n        close = ~price_close,\n        high = ~price_high,\n        low = ~price_low,\n        name = \"Candlesticks\") %&gt;%\n  layout(title = \"Candlestick de Tecnoglass\",\n         xaxis = list(title = \"Fecha\"),\n         yaxis = list(title = \"Precio\"))\n\n\n\n\n\nEl gráfico de velas muestra una tendencia general alcista, especialmente hacia las fechas mas recietes donde se observa un aumento significativo en los precios. Este patrón general sugiere que la acción ha tenido una buena recepción en el mercado, atrayendo un interés creciente de los inversores.\nConvertimos los datos de precios de cierre de Tecnoglass en una serie temporal para facilitar análisis posteriores y se define la frecuencia a 250 días hábiles por año.\n\nfrecuencia &lt;- 250  \n\ntgls_ts &lt;- ts(datos_tgls$price_close, \n              frequency = frecuencia, \n              start = c(as.integer(format(min(datos_tgls$ref_date), \"%Y\")),\n                        as.integer(format(min(datos_tgls$ref_date), \"%j\"))))\n\nComprobamos si hay valores faltantes en la serie temporal\n\nsum(is.na(tgls_ts))\n\n[1] 0\n\n\nNo hay datos faltantes en la serie, lo que significa que podemos proceder con el análisis\n\nts_plot(tgls_ts,\n        title = \"Precios de Cierre de Tecnoglass 2013-Presente\",\n        Ytitle = \"Precio de cierre\",\n        Xtitle = \"Año\")\n\n\n\n\n\nEl gráfico muestra una tendencia alcista significativa desde 2020, con una volatilidad creciente en los precios de cierre. No se aprecian patrones estacionales claros, pero sí una mayor fluctuación de precios en los últimos años, sugiriendo cambios potenciales en la dinámica del mercado o en la empresa.\n\nts_decompose(tgls_ts)\n\n\n\n\n\nLa descomposición muestra una tendencia claramente alcista, que domina sobre la estacionalidad y el componente aleatorio. La falta de una estacionalidad marcada sugiere que las decisiones de inversión y los eventos del mercado relacionados con estas acciones podrían estar más influenciados por factores específicos de la empresa o eventos del mercado más amplios en lugar de patrones estacionales.\n\nsummary(tgls_ts)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   2.29    8.85   10.18   14.81   14.92   59.00 \n\n\nEn promedio, las acciones se cotizaron a $15.09, con una mediana más baja de $10.50, indicando una distribución de precios con tendencia hacia valores más bajos, pero con picos que alcanzan hasta los $59.00\n\n# Histograma de los precios de cierre\nhist(tgls_ts, \n     main = \"Histograma de Precios de Cierre de Tecnoglass\", \n     xlab = \"Precio de cierre\", \n     breaks = \"Sturges\", \n     probability = TRUE, \n     col = \"lightblue\")\n\nlines(density(tgls_ts), col = \"darkblue\", lwd = 2)\n\n\n\n\n\n\n\n\nEl histograma revela que los precios de cierre de Tecnoglass habian permanecidos principalmente en un rango bajo, con recientes picos con valores más altos.\n\n\n\nMas alla de lo visual podemos apelar a pruebas de hipotesis para saber si la serie de tiempo es estacionaria, a traves del Test de Dickey-Fuller Aumentado.\n\nadf.test(tgls_ts, alternative = \"stationary\")\n\nWarning in adf.test(tgls_ts, alternative = \"stationary\"): p-value greater than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tgls_ts\nDickey-Fuller = -0.27629, Lag order = 14, p-value = 0.99\nalternative hypothesis: stationary\n\n\nla prueba sugiere que la serie temporal de los precios de cierre de Tecnoglass no es estacionaria y puede contener una tendencia o una estructura dependiente del tiempo que no ha sido eliminada\n\n\n\nPara evaluar la efectividad de los modelos predictivos, dividimos la serie temporal de precios de cierre en dos partes: un conjunto de entrenamiento y un conjunto de prueba. El conjunto de prueba consiste en los últimos 28 días, que reservamos para evaluar el modelo, mientras que el resto de los datos se utiliza para entrenarlo.\n\ntgls_split &lt;- ts_split(tgls_ts, sample.out = 28)\n\ntrain &lt;- tgls_split$train\ntest &lt;- tgls_split$test\n\nPara ayudar en la selección de los parámetros del modelo ARIMA, graficamos las funciones de autocorrelación (ACF) y autocorrelación parcial (PACF) para el conjunto de entrenamiento\n\npar(mfrow = c(1, 2))\nacf(train, lag.max = 250)\npacf(train, lag.max = 250)\n\n\n\n\n\n\n\n\nEl gráfico ACF muestra una disminución gradual de las autocorrelaciones que no cortan rápidamente hacia cero, lo que podría sugerir un proceso AR (autorregresivo) o la presencia de una raíz unitaria, indicando que la serie podría no ser estacionaria.\n\n\n\nAhora procedemos a diferenciar la serie de tiempo de entrenamiento para eliminar cualquier tendencia o estacionalidad y estabilizar la media.\n\ntgls_d &lt;- diff(train, 1)\n\nts_plot(tgls_d,\n        title = \"Tecnoglass - Diferenciación Estacional\",\n        Ytitle = \"Diferencia de Precios\",\n        Xtitle = \"Año\")\n\n\n\n\n\nCorroboramos estacionaridad con el Test de Dickey-Fuller Aumentado con:\n\\(\\mathit{H_0}\\) : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición no es estacionaria.\n\\(\\mathit{H_1}\\) : La serie de tiempo para el precio de cierre de TGLS tras la primera diferencición es estacionaria.\n\nadf.test(tgls_d, alternative = \"stationary\")\n\nWarning in adf.test(tgls_d, alternative = \"stationary\"): p-value smaller than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tgls_d\nDickey-Fuller = -13.579, Lag order = 14, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCon un p-valor=0.01 rechazamos la hipotesis nula de no estacionariedad. Después de tomar la diferenciación de primer orden, junto con la diferenciación estacional de primer orden, la serie parece estabilizarse en torno a la línea del eje x cero (o bastante cerca de ser estable). Después de transformar la serie en un estado estacionario, podemos revisar las funciones ACF y PACF de nuevo para identificar el proceso necesario\n\npar(mfrow=c(1,2))\nacf(tgls_d, lag.max = 250)\npacf(tgls_d, lag.max = 250)\n\n\n\n\n\n\n\n\nEn el gráfico ACF a la izquierda, las correlaciones en los primeros retrasos son bajas y parecen caer dentro del área de confianza, lo que indica que la diferenciación ha ayudado a remover cualquier autocorrelación.El gráfico PACF a la derecha muestra una cantidad significativa de picos fuera del área de confianza, lo que puede indicar que un modelo ARIMA con términos de media móvil podría ser apropiado.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "ts_r.html#punto-2",
    "href": "ts_r.html#punto-2",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "punto 2",
    "text": "punto 2\nRepita TODOS los pasos indicados en esta sección para encontrar modelos ARIMA para predecir el precio de las acciones de Tecnoglass con los siguientes horizontes: 7, 14 días, 21 días, 28 días. Utilizar siempre predicciones usando rolling con ventana de predicción continua de un día. Cualquier cantidad de pasos extra para enriquecer su análisis predictivo serán aceptados siempre y cuando sean acordes con lo que indica la teoría de análisis de series de tiempo.\nInicialmente aplicamos la función auto.arima para seleccionar de forma automática el mejor modelo ARIMA para nuestros datos de entrenamiento. Este enfoque nos permite identificar el modelo que mejor se ajusta a la serie temporal sin la neces\n\nAuto-arima\n\n# Ajuste del modelo ARIMA usando auto.arima\nif (!file.exists(\"auto_arima.rda\")) {\n  tgls_auto_model &lt;- auto.arima(train,\n                             max.order = 3,\n                             D = 1,\n                             d = 1,\n                             stepwise = FALSE,\n                             approximation = FALSE)\n  saveRDS(tgls_auto_model, \"auto_arima.rda\")\n} else {\n  tgls_auto_model &lt;- readRDS(\"auto_arima.rda\")\n}\n\n# Muestra el modelo\nprint(tgls_auto_model)\n\nSeries: train \nARIMA(3,1,0)(0,1,0)[250] \n\nCoefficients:\n         ar1      ar2     ar3\n      0.0004  -0.0670  0.0558\ns.e.  0.0192   0.0192  0.0193\n\nsigma^2 = 0.6424:  log likelihood = -3260.92\nAIC=6529.84   AICc=6529.85   BIC=6553.47\n\n\nLos resultados del auto.arima nos han proporcionado un modelo ARIMA(3,1,0)(0,1,0)[250] para nuestra serie temporal de precios de cierre de Tecnoglass, lo que sugiere que la mejor manera de entender y predecir estos datos es a través de la relación de los precios con sus tres valores anteriores y una tendencia estabilizada por diferenciación.\n\ncheckresiduals(tgls_auto_model)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,1,0)(0,1,0)[250]\nQ* = 2073.5, df = 497, p-value &lt; 2.2e-16\n\nModel df: 3.   Total lags used: 500\n\n\nlos diagnósticos de residuos del modelo ARIMA muestra que los residuos no exhiben patrones claros a lo largo del tiempo, lo cual es una buena señal de que el modelo se ajusta adecuadamente a los datos. La ACF de los residuos no muestra autocorrelaciones significativas, lo que sugiere que el modelo ha capturado bien la dinámica de la serie temporal. Además, la distribución de los residuos parece aproximadamente normal ### ARIMA con base en la minimización del coeficiente de Akaike (AIC) La función best_ARIMA prueba modelos con diferentes números de términos autoregresivos (p), de diferenciación (d), y de media móvil (q), incluyendo también sus equivalentes estacionales (P, D, Q).\n\nbest_ARIMA &lt;- function(ts_in, p_n, d_n, q_n) {\n  best_aic &lt;- Inf\n  best_pdq &lt;- NULL\n  best_PDQ &lt;- NULL\n  fit &lt;- NULL\n  for(p in 1:p_n) {\n    for(d in 1:d_n) {\n      for (q in 1:q_n) {\n        for(P in 1:p_n) {\n          for(D in 1:d_n) {\n            for (Q in 1:q_n) {\n              tryCatch({\n                fit &lt;- arima(scale(ts_in), \n                             order=c(p, d, q), \n                             seasonal = list(order = c(P, D, Q), period = 250),\n                             xreg=1:length(ts_in), \n                             method=\"CSS-ML\")\n                tmp_aic &lt;- AIC(fit)\n                if (tmp_aic &lt; best_aic) {\n                  best_aic &lt;- tmp_aic\n                  best_pdq = c(p, d, q)\n                  best_PDQ = c(P, D, Q)\n                }\n              }, error=function(e){})\n            }\n          }\n        }\n      }\n    }\n  }\n  return(list(\"best_aic\" = best_aic, \"best_pdq\" = best_pdq, \"best_PDQ\" = best_PDQ))\n}\n\n\nif(file.exists(\"best_arima.rda\")) {\n  best_model = readRDS(\"best_arima.rda\")\n} else {\n  best_model = best_ARIMA(train, 3, 1, 3)\n  saveRDS(best_model, file = \"best_arima.rda\")\n}\n\n\nprint(best_model)\n\n$best_aic\n[1] -7167.355\n\n$best_pdq\n[1] 3 1 3\n\n$best_PDQ\n[1] 1 1 1\n\n\n\nfit_model &lt;- NULL\nif(file.exists(\"TGLS_model.rda\")) {\nfit_model = readRDS(\"TGLS_model.rda\")\n} else {\n  fit_model &lt;- arima(train, order = c(3,1,3), \n                  seasonal = list(order = c(1,1,1)))\n  \n  saveRDS(fit_model, file = \"TGLS_model.rda\")\n}\n\n\nfit_model\n\n\nCall:\narima(x = train, order = c(3, 1, 3), seasonal = list(order = c(1, 1, 1)))\n\nCoefficients:\n          ar1     ar2     ar3     ma1      ma2      ma3     sar1     sma1\n      -0.0438  0.0714  0.9348  0.0486  -0.1089  -0.9119  -0.1320  -0.7509\ns.e.   0.0261  0.0251  0.0244  0.0298   0.0284   0.0281   0.0292   0.0251\n\nsigma^2 estimated as 0.3935:  log likelihood = -2725,  aic = 5467.99\n\n\nLos coeficientes estimados para los términos autoregresivos y de media móvil son estadísticamente significativos, con el tercer término AR y el tercer término MA destacándose por su magnitud. Esto sugiere una fuerte relación entre los precios actuales y los precios pasados, tanto en la tendencia general como en la estacionalidad anual.\n\ncheckresiduals(fit_model) \n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from ARIMA(3,1,3)(1,1,1)[250]\nQ* = 1303.5, df = 492, p-value &lt; 2.2e-16\n\nModel df: 8.   Total lags used: 500\n\n\nlos residuos no exhiben patrones claros a lo largo del tiempo, lo cual es una buena señal de que el modelo se ajusta adecuadamente a los datos. La ACF de los residuos no muestra autocorrelaciones significativas, lo que sugiere que el modelo ha capturado bien la dinámica de la serie temporal. Además, la distribución de los residuos parece aproximadamente normal\nComo el AIC del filt_model es menor que el generado con la funcion autoarima, procedemos a realizar las predicciones con el fitl_model.\n\n\nModelado ARIMA con Rolling Forecast:\ngeneramos la función pred_rolling, la cual es clave para simular un escenario realista de pronóstico donde el modelo ARIMA se actualiza continuamente con nuevos datos. Esta función adopta el enfoque de Rolling Forecast, reajustando el modelo de forma secuencial para cada punto de dato en el conjunto de prueba y utilizando la información más reciente disponible.\n\npred_rolling &lt;- function(historico, prueba, modelo) {\n  predicciones &lt;- numeric(length(prueba))\n  \n  for (t in seq_along(prueba)) {\n    modelo_ajustado &lt;- Arima(historico, model=modelo)\n    pronostico &lt;- forecast(modelo_ajustado, h=1)\n    predicciones[t] &lt;- pronostico$mean\n    historico &lt;- c(historico, prueba[t])\n  }\n  return(predicciones)\n}\n\nA traves de este código automatiza la evaluación y visualizacion del modelo ARIMA sobre diferentes horizontes temporales (7, 14, 21 y 28 días) para verificar su eficacia predictiva en condiciones variadas.\n\nhorizontes &lt;- c(7, 14, 21, 28)\nresults_rolling &lt;- list()\n\nfor(h in horizontes) {\n  \n  datos_split &lt;- ts_split(tgls_ts, sample.out = h)\n  train &lt;- datos_split$train\n  test &lt;- datos_split$test\n  \n  # Archivo donde se guardarán las predicciones\n  archivo_pred &lt;- paste0(\"pred_\", h, \"d_roll.rda\")\n  \n  if(!file.exists(archivo_pred)) {\n    pred_roll &lt;- pred_rolling(train, test, fit_model)\n    saveRDS(pred_roll, archivo_pred)\n  } else {\n    pred_roll &lt;- readRDS(archivo_pred)\n  }\n  \n  \n  # Crear DataFrames para la visualización\n  df_entrenamiento &lt;- data.frame(Fecha = time(train), Valor = as.numeric(train))\n  df_prueba &lt;- data.frame(Fecha = time(test), Valor = as.numeric(test))\n  df_predicciones &lt;- data.frame(Fecha = time(test), Valor = pred_roll)\n  \n  plot_name &lt;- paste0(\"plot_rolling_\", h)\n  \n  # Visualización de los resultados con Plotly\n  p &lt;- plot_ly() %&gt;%\n    add_lines(data = df_entrenamiento, x = ~Fecha, y = ~Valor, name = \"Entrenamiento\", line = list(color = '#000D61')) %&gt;%\n    add_lines(data = df_prueba, x = ~Fecha, y = ~Valor, name = \"Prueba\", line = list(color = '#00C5DF')) %&gt;%\n    add_lines(data = df_predicciones, x = ~Fecha, y = ~Valor, name = \"Predicción\", line = list(color = '#DF6401')) %&gt;%\n    layout(title = paste(\"Predicción ARIMA Rolling -\", h, \"días\"),\n           xaxis = list(title = \"Fecha\"),\n           yaxis = list(title = \"Precio\"),\n           showlegend = TRUE)\n  \n  assign(plot_name, p)\n  \n  \n  metrics &lt;- forecast::accuracy(pred_roll, test)\n  results_rolling[[paste(\"Horizon\", h, \"days\")]] &lt;- metrics\n  \n}",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "ts_r.html#gráfico-de-correlación-entre-la-observación-real-y-su-predicción",
    "href": "ts_r.html#gráfico-de-correlación-entre-la-observación-real-y-su-predicción",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "Gráfico de correlación entre la observación real y su predicción",
    "text": "Gráfico de correlación entre la observación real y su predicción\nPara evaluar y comparar la efectividad de las técnicas de predicción Rolling Forecast y Direct Forecast, analizamos la correlación entre las predicciones de cada técnica y los valores reales observados.\n\ncreate_correlation_plot &lt;- function(actual, predicted, title) {\n  data &lt;- data.frame(Actual = actual, Predicted = predicted)\n  ggplot(data, aes(x = Actual, y = Predicted)) +\n    geom_point(color = 'blue', alpha = 0.5) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n    ggtitle(paste(title, \"\\nR^2:\", round(summary(lm(Predicted ~ Actual, data = data))$r.squared, 3))) +\n    xlab(\"Valores Reales\") +\n    ylab(\"Valores Predichos\") +\n    theme_minimal()\n}\n\nplot_rolling &lt;- create_correlation_plot(test, pred_roll, \"Correlación Rolling Forecast\")\n\nplot_forecast &lt;- create_correlation_plot(test, pred$mean, \"Correlación Direct Forecast\")\n\ngrid.arrange(plot_rolling, plot_forecast, ncol = 2)\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n`geom_smooth()` using formula = 'y ~ x'\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEl método Rolling Forecast demuestra ser considerablemente más confiable y preciso, para este conjunto de datos, lo que sugiere que es el enfoque preferible para las predicciones a futuro basadas en esta serie temporal.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "ts_r.html#cirterio-bic",
    "href": "ts_r.html#cirterio-bic",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "Cirterio BIC",
    "text": "Cirterio BIC\n\nbest_ARIMA_BIC &lt;- function(ts_in, p_n, d_n, q_n) {\n  best_bic &lt;- Inf\n  best_pdq &lt;- NULL\n  best_PDQ &lt;- NULL\n  fit &lt;- NULL\n  for(p in 1:p_n) {\n    for(d in 1:d_n) {\n      for (q in 1:q_n) {\n        for(P in 1:p_n) {\n          for(D in 1:d_n) {\n            for (Q in 1:q_n) {\n              tryCatch({\n                fit &lt;- arima(scale(ts_in), \n                             order=c(p, d, q), \n                             seasonal = list(order = c(P, D, Q), period = 250),\n                             xreg=1:length(ts_in), \n                             method=\"CSS-ML\")\n                tmp_bic &lt;- BIC(fit)\n                if (tmp_bic &lt; best_bic) {\n                  best_bic &lt;- tmp_bic\n                  best_pdq &lt;- c(p, d, q)\n                  best_PDQ &lt;- c(P, D, Q)\n                }\n              }, error=function(e){})\n            }\n          }\n        }\n      }\n    }\n  }\n  return(list(\"best_bic\" = best_bic, \"best_pdq\" = best_pdq, \"best_PDQ\" = best_PDQ))\n}\n\n\nbest_model_bic &lt;- NULL\nif(file.exists(\"best_arima_bic.rda\")) {\n  best_model_bic = readRDS(\"best_arima_bic.rda\")\n} else {\n  best_model_bic = best_ARIMA_BIC(train, 3, 1, 3)\n  saveRDS(best_model_bic, file = \"best_arima_bic.rda\")\n}\n\nbest_model_bic \n\n$best_bic\n[1] -7108.267\n\n$best_pdq\n[1] 3 1 3\n\n$best_PDQ\n[1] 1 1 1",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "ts_r.html#criterio-hqic",
    "href": "ts_r.html#criterio-hqic",
    "title": "Predicciones de Series de Tiempo en R",
    "section": "Criterio HQIC",
    "text": "Criterio HQIC\n\nbest_ARIMA_HQIC &lt;- function(ts_in, p_n, d_n, q_n) {\n  best_hqic &lt;- Inf\n  best_pdq &lt;- NULL\n  best_PDQ &lt;- NULL\n  fit &lt;- NULL\n  for(p in 1:p_n) {\n    for(d in 1:d_n) {\n      for (q in 1:q_n) {\n        for(P in 1:p_n) {\n          for(D in 1:d_n) {\n            for (Q in 1:q_n) {\n              tryCatch({\n                fit &lt;- arima(scale(ts_in), \n                             order=c(p, d, q), \n                             seasonal = list(order = c(P, D, Q), period = 250),\n                             xreg=1:length(ts_in), \n                             method=\"CSS-ML\")\n                tmp_hqic &lt;- AIC(fit, k = log(length(ts_in)))\n                if (tmp_hqic &lt; best_hqic) {\n                  best_hqic &lt;- tmp_hqic\n                  best_pdq &lt;- c(p, d, q)\n                  best_PDQ &lt;- c(P, D, Q)\n                }\n              }, error=function(e){})\n            }\n          }\n        }\n      }\n    }\n  }\n  return(list(\"best_hqic\" = best_hqic, \"best_pdq\" = best_pdq, \"best_PDQ\" = best_PDQ))\n}\n\n\nbest_model_hqic &lt;- NULL\nif(file.exists(\"best_arima_hqic.rda\")) {\n  best_model_hqic = readRDS(\"best_arima_hqic.rda\")\n} else {\n  best_model_hqic = best_ARIMA_HQIC(train, 4, 1, 4)\n  saveRDS(best_model_hqic, file = \"best_arima_hqic.rda\")\n}\n\nbest_model_hqic\n\n$best_hqic\n[1] -7107.385\n\n$best_pdq\n[1] 3 1 3\n\n$best_PDQ\n[1] 1 1 1\n\n\nComo podemos notar, los resultados obtenidos para los modelos generados bajo los criterios de BIC y HQIC son iguales al obtenido mediante el criterio de AIC. Por tanto, los análisis que hiciesemos similares a los del AIC serán los mismos.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - R"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Series de tiempo",
    "section": "",
    "text": "Una serie temporal es una realización parcial de un proceso estocástico de parámetro tiempo discreto, donde los elementos de \\(I\\) están ordenados y corresponden a instantes equidistantes del tiempo. Estos procesos estocásticos son colecciones o familias de variables aleatorias \\(\\{X_{t}\\}_{t\\in I}\\) ordenadas según el subíndice \\(t\\) que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si \\(I\\) es discreto, el proceso es en tiempo discreto. Si \\(I\\) es continuo, el proceso es en tiempo continuo. Entre las series de tiempo, existen modelos estadísticos que definen el proceso de cualquier conjunto de hipótesis bien definidas sobre las propeidades estadísticas de dicho proceso estocástico.\nUno de los modelos más utilizados a la hora de realizar pronósticos de series de tiempo es el modelo ARIMA. Estos modelos ARIMA (Autorregresivos Integrados de Media Móvil) aproximan los valores futuros de una serie temporal como una función lineal de observaciones pasadas y términos de ruido blanco. Una serie de tiempo \\(y_t\\) se llama un proceso de media móvil integrada autorregresiva (ARIMA) de órdenes \\(p, d, q\\), denotado ARIMA(\\(p, d, q\\)) si su diferencia \\(d\\) da lugar a un proceso estacionario ARMA(\\(p, q\\)). Por lo tanto, un ARIMA(\\(p, d, q\\)) puede escribirse como\n\\[\n    \\Phi(B)(1 - B)^{d} y_{t} = \\delta + \\Theta(B) \\varepsilon_{t}\n\\]\ndonde\n\\[\n    \\Phi(B) = 1 - \\sum_{i = 1}^{p} \\phi_{i} B^{i} \\quad \\text{y} \\quad \\Theta(B) = 1 - \\sum_{i = 1}^{q} \\theta_{i} B^{i},\n\\]\nson los términos del operador back-shit en los AR(\\(p\\)) y MA(\\(q\\)) definidos como \\(\\Phi(B) y_{t} = \\delta + \\varepsilon_{t}\\) y \\(y_{t} = \\mu + \\Theta(B) \\varepsilon_{t}\\) con \\(\\delta = \\mu - \\phi \\mu\\), donde \\(\\mu\\) es la media y \\(\\varepsilon_{t}\\) el ruido blanco con \\(E(\\varepsilon_t) = 0\\) (Rubio 2024).\n\n\n\n\nReferencias\n\nRubio, Lihki. 2024. «Predicciones de series de tiempo con Python». 2024. https://lihkir.github.io/DataVizPythonRUninorte/predictive_model.html.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "ts_python.html",
    "href": "ts_python.html",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "",
    "text": "Para este proyecto trabajaremos con las siguientes librerías:\n\nPandas\nPlotly\nMatplotlib\nSeaborn\nYfinance\nNumpy\nStatsmodel\n\nPueden instalarse utilizando el siguiente comando desde la terminal: pip install pandas yfinance plotly..., o bien, mediante el archivo requirements.txt utilizando pip install -r requirements.txt en la terminal.\nUna vez instaladas, podemos importarlas en nuestro entorno de trabajo de la siguiente manera:\n\nimport os\nimport pickle\n\nimport pandas as pd\nimport numpy as np\nfrom numpy import log\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\nfrom datetime import datetime, timedelta\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_predict\nfrom statsmodels.tsa.arima.model import ARIMA, ARIMAResults\n\nfrom sklearn.metrics import r2_score\nfrom scipy.stats import shapiro\n\nimport pmdarima as pm\n\nfrom functools import lru_cache\nimport time\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#series-estacionarias",
    "href": "ts_python.html#series-estacionarias",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Series estacionarias",
    "text": "Series estacionarias\nPara determinar si nuestra serie de tiempo es estacionaria, recurrimos al conocido test estadístico de Dickey-Fuller. Este test plantea las siguientes hipótesis:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{La serie de tiempo no es estacionaria}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{La serie de tiempo es estacionaria}\n\\end{gather}\n\\]\nEl objetivo es no rechazar la hipótesis nula. Por lo tanto, evaluamos el resultado del test mediante el siguiente código:\n\nresult: tuple = adfuller(stock_data.Close)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\n\nADF Statistic: -0.730010\np-value: 0.838822\n\n\nDado que (p-valor &gt; 0.05), no rechazamos la hipótesis nula, lo que indica que la serie de tiempo es estacionaria. Esta conclusión se refuerza al analizar gráficamente la autocorrelación, lo que también nos permite entender el orden de integración necesario para transformar la serie de no estacionaria a estacionaria.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#autocorrelación",
    "href": "ts_python.html#autocorrelación",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Autocorrelación",
    "text": "Autocorrelación\nExaminemos estas gráficas de autocorrelación para las diferentes diferenciaciones de nuestra serie de tiempo, utilizando un número de retrasos (lags) de 240:\n\nplt.rcParams.update({'figure.figsize': (9, 9)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(stock_data.Close); axes[0, 0].set_title('Original Series')\nplot_acf(stock_data.Close, ax=axes[0, 1], lags = 240);\n\naxes[1, 0].plot(stock_data.Close.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(stock_data.Close.diff().dropna(), ax=axes[1, 1], lags = 240);\n\naxes[2, 0].plot(stock_data.Close.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(stock_data.Close.diff().diff().dropna(), ax=axes[2, 1], lags = 240);\n\n\n\n\nAutocorrelación de la serie de tiempo original, diferenciada 1 vez y 2 veces.\n\n\n\n\nSe observa que la gráfica de autocorrelación de la serie de tiempo original muestra un decaimiento con tendencia lineal o geométrica, lo que indica una autocorrelación típica de una serie no estacionaria. Además, observamos un fenómeno de sobrediferenciación en la gráfica de la segunda diferenciación, donde la autocorrelación ingresa rápidamente a la zona negativa.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterios-aic-bic-y-hqic",
    "href": "ts_python.html#criterios-aic-bic-y-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterios AIC, BIC y HQIC",
    "text": "Criterios AIC, BIC y HQIC\nLos criterios de información de Akaike (AIC), Bayesiano (BIC) y de Hannan-Quinn (HQIC) utilizan el método de estimación de máxima verosimilitud (log-verosimilitud) de los modelos como medida de ajuste. Estas medidas buscan valores bajos para indicar un mejor ajuste del modelo a los datos, empleando las siguientes fórmulas:\n\\[\n\\begin{align*}\n    \\text{AIC} &= 2k - 2 \\ln(L) \\\\\n    \\text{BIC} &= k \\ln(n) - 2 \\ln(L) \\\\\n    \\text{HQIC} &= 2k \\ln(\\ln(n)) - 2 \\ln(L).\n\\end{align*}\n\\]\ndonde \\(k\\) representa el número de parámetros en el modelo estadístico, \\(L\\) el valor de la función de máxima verosimilitud del modelo estimado, y \\(n\\) el tamaño de la muestra.\nEs importante destacar que, aunque aumentar el número de parámetros puede aumentar el valor de la verosimilitud, esto puede conducir a problemas de sobreajuste en el modelo. Para abordar este problema, los criterios mencionados anteriormente introducen un término de penalización basado en el número de parámetros. El término de penalización es mayor en el BIC que en el AIC para muestras superiores a 7. Por su parte, el HQIC busca equilibrar esta penalización, situándose entre el AIC y el BIC. La elección del criterio a utilizar dependerá del objetivo principal de la investigación.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "href": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "División de datos para entrenamiento del modelo",
    "text": "División de datos para entrenamiento del modelo\nAhora procederemos a definir nuestro conjunto de datos para entrenar el modelo. Definiremos inicialmente nuestro conjunto de prueba con un horizonte de 28 días pues, este abarcará también los casos en que queramos realizar pronósticos con horizontes de 7, 14 y 21 días.\n\nn: int = len(stock_data.Close)\nn_test: int = 28\n\ntrain_size: int = n - n_test\n\ntrain: pd.DataFrame = stock_data.Close[:train_size]\ndates_train: pd.DataFrame = stock_data.Date[:train_size]\n\ntest28: pd.DataFrame = stock_data.Close[train_size:train_size + n_test]\ndates_test28: pd.DataFrame = stock_data.Date[train_size:train_size + n_test]",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-arima",
    "href": "ts_python.html#modelo-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ARIMA",
    "text": "Modelo ARIMA\nUtilizaremos el modelo ARIMA a través de la biblioteca statsmodels para explorar diferentes combinaciones de órdenes \\(p, d, q\\). Utilizaremos el método de máxima verosimilitud (method = 'mle') para calcular la verosimilitud exacta mediante el filtro de Kalman.\nComencemos creando una función que tome un dataframe de entrenamiento y devuelva el mejor conjunto de órdenes \\(p, d, q\\) asociados al criterio AIC de bondad de ajuste, junto con los valores de AIC y BIC, y el mejor modelo encontrado.\nRecordemos que, el valor \\(d\\) corresponde al número de diferenciaciones que podemos realizar a nuestra serie de tiempo. Teniendo en cuenta las gráficas de autocorrelación y la prueba de Dickey-Fuller realizada, podemos saber que el máximo valor que puede tomar \\(d\\) será de 1 diferenciación a la serie de tiempo.\n\ndef arima_model(train: pd.DataFrame, criteria: str) -&gt; tuple:\n    best_order: tuple = None\n    best_mdl: ARIMAResults = None\n\n    p_rng: range = range(2)\n    d_rng: range = range(2)\n    q_rng: range = range(3)\n\n\n    print(f'Minimizing {criteria.upper()} to find best model')\n    if criteria == 'aic':\n        best_aic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_aic: float = tmp_mdl.aic\n                        if tmp_aic &lt; best_aic:\n                            best_aic = tmp_aic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: AIC = {best_aic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_aic, best_mdl\n    elif criteria == 'bic':\n        best_bic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_bic: float = tmp_mdl.bic\n                        if tmp_bic &lt; best_bic:\n                            best_bic = tmp_bic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: BIC = {best_bic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_bic, best_mdl\n    else:\n        best_hqic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_hqic: float = tmp_mdl.hqic\n                        if tmp_hqic &lt; best_hqic:\n                            best_hqic = tmp_hqic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: HQIC = {best_hqic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_hqic, best_mdl\n\nA continuación, evaluemos nuestro conjunto de entrenamiento para obtener el mejor orden, AIC y el mejor modelo ARIMA. Antes de proceder, conviene crear una función que busque el modelo en una ruta especificada y, en caso de existir, lo cargue, o en su defecto, lo guarde si no se encuentra disponible en esa ubicación.\n\ndef get_model(filename: str, train: pd.DataFrame, criteria: str) -&gt; tuple:\n    if os.path.isfile(filename):\n        with open(filename, 'rb') as f:\n            return pickle.load(f)\n    else:\n        order, c, model = arima_model(train, criteria)\n\n        model_data = (order, c, model)\n        with open(filename, 'wb') as f:\n            pickle.dump(model_data, f)\n\n        return order, c, model\n\n\norder: tuple\naic: float\nmodel: ARIMAResults\n\norder, aic, model = get_model(\"arima_model_aic.pkl\", train, 'aic')\n\n\n\nBest model: ARIMA(1, 1, 2) | Best AIC: 56395.905\nTotal fit time: 0.08 sec",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#auto-arima",
    "href": "ts_python.html#auto-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Auto ARIMA",
    "text": "Auto ARIMA\nTambién tenemos la opción de obtener el modelo ARIMA utilizando una función llamada auto_arima. Sin embargo, esta función genera un simple random walk \\(x_{t} = x_{t - 1} + \\omega_{t}\\), que predice puramente basado en el valor temporal anterior \\(t - 1\\).\n\nauto_arima: pm.arima.auto_arima = pm.arima.auto_arima(\n    train, start_p=1, start_q=1,\n    test='adf',\n    max_p=3, max_q=3,\n    m=1,\n    d=None,\n    seasonal=False,\n    start_P=0, \n    D=0, \n    trace=True,\n    error_action='ignore',  \n    suppress_warnings=True, \n    stepwise=True\n)\n\nPerforming stepwise search to minimize aic\n ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=56402.531, Time=6.73 sec\n ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=56402.437, Time=0.05 sec\n ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=56400.953, Time=0.05 sec\n ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=56401.094, Time=0.42 sec\n ARIMA(0,1,0)(0,0,0)[0]             : AIC=56402.068, Time=0.03 sec\n ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=56401.721, Time=0.14 sec\n ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=56400.991, Time=1.38 sec\n ARIMA(1,1,0)(0,0,0)[0]             : AIC=56400.701, Time=0.04 sec\n ARIMA(2,1,0)(0,0,0)[0]             : AIC=56401.395, Time=0.19 sec\n ARIMA(1,1,1)(0,0,0)[0]             : AIC=56402.204, Time=0.79 sec\n ARIMA(0,1,1)(0,0,0)[0]             : AIC=56400.839, Time=0.13 sec\n ARIMA(2,1,1)(0,0,0)[0]             : AIC=56396.383, Time=0.60 sec\n ARIMA(3,1,1)(0,0,0)[0]             : AIC=56396.769, Time=1.72 sec\n ARIMA(2,1,2)(0,0,0)[0]             : AIC=inf, Time=17.29 sec\n ARIMA(1,1,2)(0,0,0)[0]             : AIC=56395.905, Time=24.02 sec\n ARIMA(0,1,2)(0,0,0)[0]             : AIC=56401.227, Time=14.52 sec\n ARIMA(1,1,3)(0,0,0)[0]             : AIC=56396.378, Time=19.39 sec\n ARIMA(0,1,3)(0,0,0)[0]             : AIC=56399.762, Time=7.29 sec\n ARIMA(2,1,3)(0,0,0)[0]             : AIC=56399.224, Time=8.17 sec\n ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=56396.596, Time=20.52 sec\n\nBest model:  ARIMA(1,1,2)(0,0,0)[0]          \nTotal fit time: 123.675 seconds\n\n\nCon esto, podemos notar que el valor del AIC obtenido es más bajo en el modelo obtenido mediante la función arima_model que en el modelo generado por la función auto_arima. Esta discrepancia se debe a que la función auto_arima se basa únicamente en el dato anterior para realizar predicciones, lo cual no se ajusta adecuadamente al análisis que deseamos realizar. La naturaleza cambiante de los mercados financieros, especialmente en el caso de activos como Bitcoin, que son altamente volátiles, requiere un enfoque más sofisticado que considere la evolución histórica para comprender mejor sus comportamientos.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-ajustado",
    "href": "ts_python.html#modelo-ajustado",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ajustado",
    "text": "Modelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de Akaike. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\ndef fitted_model(train: pd.DataFrame, order: tuple) -&gt; list:\n    model_arima: ARIMA = ARIMA(train, order=order)\n    model_fit: ARIMAResults = model_arima.fit()\n\n    fig: plt.Figure\n    ax: np.ndarray\n\n    plt.rcParams.update({'figure.figsize': (9,9)})\n\n    fig, ax = plt.subplots();\n    plot_predict(model_fit, 1, ax=ax);\n    plt.show();\n\n    return model_arima, model_fit\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\nDespués de obtener el modelo ajustado y visualizar la gráfica resultante, podemos observar que el rango del intervalo de confianza para las predicciones es estrecho. Esto sugiere que los pronósticos que estamos obteniendo podrían estar ajustándose correctamente a partir de los datos de entrenamiento.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "href": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Pronóstico continuo (Rolling Forecast)",
    "text": "Pronóstico continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\ndef arima_rolling(history: list, test: list, best_order: tuple) -&gt; list:\n    predictions: list = []\n\n    for t in range(len(test)):\n        model: ARIMA = ARIMA(history, order=best_order)\n        model_fit: ARIMAResults = model.fit()\n        output: tuple = model_fit.forecast()\n        yhat: float = output[0]\n        predictions.append(yhat)\n        obs: float = test[t]\n        history.append(obs)\n        print('predicted=%f, expected=%f' % (yhat, obs))\n\n    return predictions\n\ntrain_list: list = train.tolist()\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\ntest7: pd.DataFrame = stock_data.Close[train_size:train_size + 7]\ndates_test7: pd.DataFrame = stock_data.Date[train_size:train_size + 7]\n\ntest7: list = test7.tolist()\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\ntest14: pd.DataFrame = stock_data.Close[train_size:train_size + 14]\ndates_test14: pd.DataFrame = stock_data.Date[train_size:train_size + 14]\n\ntest14: list = test14.tolist()\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\ntest21: pd.DataFrame = stock_data.Close[train_size:train_size + 21]\ndates_test21: pd.DataFrame = stock_data.Date[train_size:train_size + 21]\n\ntest21: list = test21.tolist()\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\ntest28: list = test28.tolist()\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=62061.895128, expected=67913.671875\npredicted=67543.583003, expected=65491.390625\npredicted=65617.962481, expected=63778.761719\npredicted=63827.031741, expected=64062.203125\npredicted=63953.197913, expected=67234.171875\npredicted=67000.837453, expected=69958.812500\npredicted=69912.449996, expected=69987.835938\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=70099.062541, expected=67913.671875\npredicted=68121.268978, expected=65491.390625\npredicted=65673.922849, expected=63778.761719\npredicted=63860.940072, expected=64062.203125\npredicted=64042.321557, expected=67234.171875\npredicted=67132.316876, expected=69958.812500\npredicted=69915.270838, expected=69987.835938\npredicted=70075.230679, expected=69455.343750\npredicted=69565.806971, expected=70744.953125\npredicted=70781.195373, expected=69892.828125\npredicted=70015.961974, expected=69645.304688\npredicted=69736.097246, expected=71333.648438\npredicted=71346.181357, expected=69702.148438\npredicted=69852.378153, expected=65446.972656\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=65618.583610, expected=67913.671875\npredicted=67837.288297, expected=65491.390625\npredicted=65562.948111, expected=63778.761719\npredicted=63785.400704, expected=64062.203125\npredicted=63956.590833, expected=67234.171875\npredicted=67097.724028, expected=69958.812500\npredicted=69884.467129, expected=69987.835938\npredicted=70041.805917, expected=69455.343750\npredicted=69533.794209, expected=70744.953125\npredicted=70732.579624, expected=69892.828125\npredicted=69985.388050, expected=69645.304688\npredicted=69708.213788, expected=71333.648438\npredicted=71319.233696, expected=69702.148438\npredicted=69824.909341, expected=65446.972656\npredicted=65644.821635, expected=65980.812500\npredicted=65966.309575, expected=68508.843750\npredicted=68420.036194, expected=67837.640625\npredicted=67885.662403, expected=68896.109375\npredicted=68879.449663, expected=69362.554688\npredicted=69374.521537, expected=71631.359375\npredicted=71583.371847, expected=69139.015625\n\nARIMA Rolling - Horizonte de 28 días\npredicted=69287.033459, expected=67913.671875\npredicted=67994.333491, expected=65491.390625\npredicted=65597.118347, expected=63778.761719\npredicted=63832.588762, expected=64062.203125\npredicted=64029.900746, expected=67234.171875\npredicted=67106.747346, expected=69958.812500\npredicted=69883.610835, expected=69987.835938\npredicted=70018.542161, expected=69455.343750\npredicted=69506.265640, expected=70744.953125\npredicted=70735.554824, expected=69892.828125\npredicted=69956.800223, expected=69645.304688\npredicted=69685.024265, expected=71333.648438\npredicted=71309.180755, expected=69702.148438\npredicted=69793.458480, expected=65446.972656\npredicted=65601.354080, expected=65980.812500\npredicted=65960.437174, expected=68508.843750\npredicted=68385.869406, expected=67837.640625\npredicted=67865.086195, expected=68896.109375\npredicted=68863.541074, expected=69362.554688\npredicted=69335.889689, expected=71631.359375\npredicted=71583.264500, expected=69139.015625\npredicted=69214.227780, expected=70587.882812\npredicted=70560.793444, expected=70060.609375\npredicted=70104.859968, expected=67195.867188\npredicted=67363.595050, expected=63821.472656\npredicted=63922.454408, expected=65738.726562\npredicted=65699.376228, expected=63426.210938\npredicted=63489.701088, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Observamos cómo los pronósticos se ajustan a las respuestas esperadas a medida que el “tiempo” transcurre. Esto se evidencia porque al inicio, los pronósticos están un poco alejados de la realidad, pero con el tiempo, la línea de pronóstico se ajusta más al comportamiento del conjunto de prueba. Este ajuste ocurre porque en cada predicción que realizamos, estamos tomando en cuenta el valor de prueba anterior como dato histórico. Esto permite que la serie de tiempo se adapte a los cambios que ocurren a lo largo de los días.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#análsis-de-residuales",
    "href": "ts_python.html#análsis-de-residuales",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Análsis de residuales",
    "text": "Análsis de residuales\n\nTest de normalidad\nRealizar un test de normalidad es importante porque nos ayuda a determinar la distribución de nuestros datos. Con ello, podemos evaluar si nuestros datos se ajustan lo suficientemente bien a una distribución normal para utilizar métodos estadísticos paramétricos de manera adecuada. Si los datos no son normales, es posible que necesitemos aplicar métodos estadísticos no paramétricos o considerar transformaciones de datos para cumplir con los supuestos necesarios para nuestros análisis.\nPara esta prueba, utilizaremos el test de normalidad de Shapiro-Wilks, el cual sirve para “medir el grado de ajuste a una recta de las observaciones de la muestra representadas en un gráfico de probabilidad normal, de forma que se rechazará la hipótesis nula de normalidad cuando el ajuste sea malo, situación que se corresponde con valores pequeños del estadístico de contraste. Este contraste es el más adecuado cuando el tamaño de muestra es pequeño (no superior a 3000) y tampoco requiere que los parámetros de la distribución estén especificados” (Álvarez, González, y Mangin 2006). El estadístico de prueba se calcula como:\n\\[\n    W = \\frac{\\left(\\sum_{i = 1}^n a_i x_{(i)}\\right)^2}{\\sum_{i = 1}^n \\left(x_i - \\bar{x}\\right)^2},\n\\]\ndonde \\(x_{(i)}\\) son los datos de la muestra en la posición \\(i\\), \\(\\bar{x}\\) representa la media de los datos y \\(a_i\\) se calcula de la siguiente manera:\n\\[\n    \\left(a_1, a_2, \\dots, a_n\\right) = \\frac{m^\\top V^{-1}}{\\left(m^\\top V^{-1} V^{-1} m\\right)},\n\\]\nsiendo \\(m\\) los valores medios del estadístico ordenado de distribuciones normales y \\(V\\) la matriz varianzas-covarianzas de ese estadístico (Shapiro y Wilk 1965). La prueba de hipótesis se plantea como:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{Los datos siguen una distribución normal}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{Los datos no siguen una distribución normal}\n\\end{gather}\n\\]\nPara no rechazar la hipótesis nula, el p-valor debe ser mayor que \\(0.05\\) o el estadístico \\(W\\) no debe ser demasiado pequeño.\nAhora, para realizar esta prueba de normalidad de nuestros residuales, crearemos una función llamada normality que nos permitirá realizar estas pruebas a lo largo de este análisis.\n\ndef normality(model: ARIMAResults) -&gt; None:\n    qq: Figure\n    stat: float\n    pvalue: float\n\n    qq = model.plot_diagnostics(figsize=(9,9))\n\n    stat, pvalue = shapiro(model.resid)\n\n    print('Shapiro-Wilks Test')\n    print('Alternative Hipothesis: Data is not distributed normally')\n    print(f'Statistic = {stat:.3f}')\n    print(f'P-Value = {pvalue}')\n    if(pvalue &lt; 0.05):\n        print('Se rechaza la hipótesis nula, los residuales no siguen una distribución normal.')\n    else:\n        print('No se rechaza la hipótesis nula, los residuales siguen una distribución normal.')\n\nEvualuemos nuestro modelo en la función creada\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.7406507906788266e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de Independencia\nEl test de independencia es crucial en estadística para determinar si existe una asociación significativa entre variables en una población. Uno de los principales supuestos de los modelos es que no existe autocorrelación entre los residuales, es decir, son independendientes. La autocorrelación es la similitud de una serie de tiempo en intervalos de tiempo sucesivos. Puede dar lugar a subestimaciones del error estándar y hacer que piense que los predictores son significativos cuando no lo son.\nUna forma de determinar si se cumple este supuesto es realizar una prueba de Durbin-Watson, que se utiliza para detectar la presencia de autocorrelación en los residuos. La prueba de Durbin-Watson utiliza la siguiente prueba de hipótesis:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{No existe correlación entre los residuales}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{Los residuos están correlacionados}\n\\end{gather}\n\\]\nEl estadístico de prueba para la prueba de Durbin-Watson, normalmente denotado \\(d\\), se calcula de la siguiente manera:\n\\[\n    d = \\frac{\\sum_{i = 1}^T \\left(e_{t} - e_{t - 1}\\right)^2}{\\sum_{i = 1}^T e_t^2},\n\\]\ndonde \\(T\\) es el número de observaciones y \\(e_t\\) el t-ésimo residual del modelo.\nEl estadístico de prueba siempre varía de 0 a 4, donde:\n\n\\(d = 2\\), indica que no hay autocorrelación.\n\\(d &lt; 2\\), indica que existe correlación serial positiva.\n\\(d &gt; 2\\), indica que existe correlación serial negativa.\n\nEn general, si d es menor que \\(1.5\\) o mayor que \\(2.5\\), existe un problema de autocorrelación potencialmente grave. De lo contrario, si \\(d\\) está entre \\(1.5\\) y \\(2.5\\), es probable que la autocorrelación no sea motivo de preocupación (Bartels y Goodhew 1981).\nAhora, para realizar esta prueba de independencia de nuestros residuales, crearemos una función llamada autocorrelation que nos permitirá realizar estas pruebas a lo largo de este análisis.\n\ndef autocorrelation(model: ARIMAResults) -&gt; None: \n    dw = durbin_watson(model.resid)\n\n    print('Durbin-Watson Test')\n    print('Alternative Hipothesis: Residuals are correlated')\n    print(f'Statistic d = {dw:.3f}')\n    if(dw &lt; 1.5 or dw &gt; 2.5):\n        print('Se rechaza la hipótesis nula, los residuales están correlacionados.')\n    else:\n        print('No se rechaza la hipótesis nula, no existe correlación entre los residuales.')\n\nEvaluamos nuestro modelo:\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 1.984\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-bic",
    "href": "ts_python.html#criterio-bic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio BIC",
    "text": "Criterio BIC\n\norder: tuple\nbic: float\nmodel: ARIMAResults\n\norder, bic, model = get_model(\"arima_model_bic.pkl\", train, 'bic')\n\n\n\nBest model: ARIMA(0, 1, 0) | Best BIC: 56408.2204598203\nTotal fit time: 0.05 sec\n\n\nBasándonos en el resultado obtenido para el mejor orden y el valor del mejor BIC, podemos afirmar que el modelo que mejor se ajusta, de los realizados hasta ahora, sería el obtenido mediante el criterio de Akaike, Orden: (1, 1, 2) y AIC: 56395.90534927711.\n\nModelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de inferencia Bayesiana. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\n Al igual que para el modelo ajustado mediante el mejor orden obtenido por el criterio de Akaike, podemos observar que el rango del intervalo de confianza correspondiente a las predicciones es pequeño, lo que nos permite pensar que las predicciones se ajustan de manera correcta a los datos de entrenamiento.\n\n\nPronóstico Continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=63811.863281, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=69987.835938, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=65446.972656, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\n\nARIMA Rolling - Horizonte de 28 días\npredicted=69139.015625, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=63426.210938\npredicted=63426.210938, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Los resultados obtenidos de estos pronósticos son bastante similares a los que observamos anteriormente mediante el criterio AIC. Esto nos podría permitir afirmar que entre el criterio AIC y BIC no hay mucha diferencia en los resultados obtenidos para nuestra serie de tiempo.\n\n\nModelo ARIMA sin usar rolling\nRepita el paso 2 ahora sin utilizar rolling. Esto es, realice el pronóstico solo utilizando forecast() para los diferentes horizontes de predicción 7, 14, 21 y 28 días.\nPara realizar el pronóstico sin usar rolling lo único que debemos modificar de nuestra función anterior es eliminar la línea de código donde estamos guardando en el conjunto de datos history el valor observado del test. Es decir, este conjunto en nuestra nueva función ya no variará sino que será estático para cada una de las predicciones realizadas.\n\nprint('ARIMA sin Rolling - Horizonte de 7 días.')\nyhat7_nor: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 14 días.')\nyhat14_nor: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 21 días.')\nyhat21_nor: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 28 días')\nyhat28_nor: list = arima_rolling(train_list, test28, order)\n\nARIMA sin Rolling - Horizonte de 7 días.\npredicted=63811.863281, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\n\nARIMA sin Rolling - Horizonte de 14 días.\npredicted=69987.835938, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\n\nARIMA sin Rolling - Horizonte de 21 días.\npredicted=65446.972656, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\n\nARIMA sin Rolling - Horizonte de 28 días\npredicted=69139.015625, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=63426.210938\npredicted=63426.210938, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días sin usar rolling\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarmente, en el caso del criterio AIC, observamos que al inicio de las líneas de pronóstico, los resultados son similares a los obtenidos al usar rolling para realizar nuestras predicciones. Esto se debe a que, como se mencionó anteriormente, en el método rolling forecasting también utilizamos los datos de test como datos históricos. Sin embargo, también podemos notar que a medida que transcurren los días, la gráfica sigue un comportamiento similar. Esto indica que el modelo ajustado con rolling forecasting no está explicando mejor los datos que cuando no usamos esta técnica de media móvil. Ahora que examinemos las métricas obtenidas de nuestros modelos, podremos confirmar si los resultados también son similares.\n\n\nComparación entre modelos\nPara obtener las métricas de los modelos generados usaremos la función forest_accuracy creada anteriormente.\nObtengamos inicialmente las métricas para el modelo usando rolling\n\naccuracy7: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7), \"7 días\")\naccuracy14: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14), \"14 días\")\naccuracy21: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21), \"21 días\")\naccuracy28: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28), \"28 días\")\n\nAhora, obtengamos las métricas para el modelo obtenido sin usar rolling\n\naccuracy7_nor: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7_nor), \"7 días no rolling\")\naccuracy14_nor: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14_nor), \"14 días no rolling\")\naccuracy21_nor: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21_nor), \"21 días no rolling\")\naccuracy28_nor: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28_nor), \"28 días no rolling\")\n\naccuracy: pd.DataFrame = pd.concat([accuracy7, accuracy14, accuracy21, accuracy28, accuracy7_nor, accuracy14_nor, accuracy21_nor, accuracy28_nor])\n\naccuracy\n\n\n\n\n\n\n\n\n\nMAE\nMSE\nMAPE\nRMSE\nR2\n\n\n\n\n7 días\n2063.684710\n6.170230e+06\n0.031571\n2483.994814\n-0.085016\n\n\n14 días\n1636.779855\n4.072984e+06\n0.024020\n2018.163546\n0.320933\n\n\n21 días\n1586.980469\n3.744183e+06\n0.023356\n1934.989183\n0.236080\n\n\n28 días\n1604.140485\n3.756698e+06\n0.023619\n1938.220342\n0.409721\n\n\n7 días no rolling\n2063.684710\n6.170230e+06\n0.031571\n2483.994814\n-0.085016\n\n\n14 días no rolling\n1636.779855\n4.072984e+06\n0.024020\n2018.163546\n0.320933\n\n\n21 días no rolling\n1586.980469\n3.744183e+06\n0.023356\n1934.989183\n0.236080\n\n\n28 días no rolling\n1604.140485\n3.756698e+06\n0.023619\n1938.220342\n0.409721\n\n\n\n\n\n\n\n\nLos resultados obtenidos mediante el criterio de Inferencia Bayesiana (BIC) muestran una consistencia notable con los resultados anteriores obtenidos a través del criterio de Akaike (AIC). Ambos conjuntos de métricas presentan patrones similares en cuanto a la comparación entre modelos con y sin el uso de rolling. En general, los modelos con rolling tienden a ofrecer un rendimiento superior en todas las métricas evaluadas en comparación con los modelos sin rolling. Esto sugiere que, independientemente del criterio de selección del modelo utilizado, el enfoque de rolling parece ser beneficioso para la precisión de la predicción en este contexto particular. Además, se destaca que los valores de MAE, MSE, MAPE, RMSE y R2 son consistentes entre los modelos con y sin rolling para cada intervalo de predicción, lo que indica que el enfoque de rolling no solo mejora la precisión, sino también la estabilidad de los modelos de predicción.\n\nplt.rcParams.update({'figure.figsize': (9, 16)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(4)\n\nsns.scatterplot(x=test7, y=yhat7, ax=axes[0], color='#5a189a', label='Real vs Estimado')\naxes[0].plot(test7, test7, color='#c77dff', label='Correlación')\naxes[0].set_title('Horizonte 7 días', fontsize=12)\n\nsns.scatterplot(x=test14, y=yhat14, ax=axes[1], color='#5a189a', label='Real vs Estimado')\naxes[1].plot(test14, test14, color='#c77dff', label='Correlación')\naxes[1].set_title('Horizonte 14 días', fontsize=12)\n\nsns.scatterplot(x=test21, y=yhat21, ax=axes[2], color='#5a189a', label='Real vs Estimado')\naxes[2].plot(test21, test21, color='#c77dff', label='Correlación')\naxes[2].set_title('Horizonte 21 días', fontsize=12)\n\nsns.scatterplot(x=test28, y=yhat28, ax=axes[3], color='#5a189a', label='Real vs Estimado')\naxes[3].plot(test28, test28, color='#c77dff', label='Correlación')\naxes[3].set_title('Horizonte 28 días', fontsize=12)\n\nText(0.5, 1.0, 'Horizonte 28 días')\n\n\n\n\n\n\n\n\n\n Nuevamente, podemos observar que a medida que las ventanas de predicción aumentan, los valores predichos se ajustan más a la línea del test. Lo que reafirma la idea de que la técnica de las predicciones utilizando la media móvil (rolling) es efectiva para este tipo de modelos.\n\n\nAnálisis de los residuales\n\nTest de normalidad\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.672904862089655e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de independencia\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 2.048\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-hqic",
    "href": "ts_python.html#criterio-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio HQIC",
    "text": "Criterio HQIC\n\norder: tuple\nhqic: float\nmodel: ARIMAResults\n\norder, hqic, model = get_model(\"arima_model_hqic.pkl\", train, 'hqic')\n\n\n\nBest model: ARIMA(0, 1, 0) | Best HQIC: 56404.26483697662\nTotal fit time: 0.04 sec\n\n\nNotemos que el orden obtenido es el mismo que el obtenido para el criterio BIC. Por tanto, los resultados que se obtendrían si siguieramos con el análisis planteado anteriormente serían iguales.\n\nAnálisis de residuales\n\nTest de normalidad\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.672904862089655e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de independencia\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 2.048\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  }
]