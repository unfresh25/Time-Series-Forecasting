[
  {
    "objectID": "ts_python.html",
    "href": "ts_python.html",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "",
    "text": "Para este proyecto trabajaremos con las siguientes librerías:\n\nPandas\nPlotly\nMatplotlib\nSeaborn\nYfinance\nNumpy\nStatsmodel\n\nPueden instalarse utilizando el siguiente comando desde la terminal: pip install pandas yfinance plotly..., o bien, mediante el archivo requirements.txt utilizando pip install -r requirements.txt en la terminal.\nUna vez instaladas, podemos importarlas en nuestro entorno de trabajo de la siguiente manera:\n\nimport os\nimport pickle\n\nimport pandas as pd\nimport numpy as np\nfrom numpy import log\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport yfinance as yf\n\nfrom datetime import datetime, timedelta\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_predict\nfrom statsmodels.tsa.arima.model import ARIMA, ARIMAResults\n\nfrom sklearn.metrics import r2_score\nfrom scipy.stats import shapiro\n\nimport pmdarima as pm\n\nfrom functools import lru_cache\nimport time\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#series-estacionarias",
    "href": "ts_python.html#series-estacionarias",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Series estacionarias",
    "text": "Series estacionarias\nPara determinar si nuestra serie de tiempo es estacionaria, recurrimos al conocido test estadístico de Dickey-Fuller. Este test plantea las siguientes hipótesis:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{La serie de tiempo no es estacionaria}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{La serie de tiempo es estacionaria}\n\\end{gather}\n\\]\nEl objetivo es no rechazar la hipótesis nula. Por lo tanto, evaluamos el resultado del test mediante el siguiente código:\n\nresult: tuple = adfuller(stock_data.Close)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\n\nADF Statistic: -0.730010\np-value: 0.838822\n\n\nDado que (p-valor &gt; 0.05), no rechazamos la hipótesis nula, lo que indica que la serie de tiempo es estacionaria. Esta conclusión se refuerza al analizar gráficamente la autocorrelación, lo que también nos permite entender el orden de integración necesario para transformar la serie de no estacionaria a estacionaria.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#autocorrelación",
    "href": "ts_python.html#autocorrelación",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Autocorrelación",
    "text": "Autocorrelación\nExaminemos estas gráficas de autocorrelación para las diferentes diferenciaciones de nuestra serie de tiempo, utilizando un número de retrasos (lags) de 240:\n\nplt.rcParams.update({'figure.figsize': (9, 9)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(stock_data.Close); axes[0, 0].set_title('Original Series')\nplot_acf(stock_data.Close, ax=axes[0, 1], lags = 240);\n\naxes[1, 0].plot(stock_data.Close.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(stock_data.Close.diff().dropna(), ax=axes[1, 1], lags = 240);\n\naxes[2, 0].plot(stock_data.Close.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(stock_data.Close.diff().diff().dropna(), ax=axes[2, 1], lags = 240);\n\n\n\n\nAutocorrelación de la serie de tiempo original, diferenciada 1 vez y 2 veces.\n\n\n\n\nSe observa que la gráfica de autocorrelación de la serie de tiempo original muestra un decaimiento con tendencia lineal o geométrica, lo que indica una autocorrelación típica de una serie no estacionaria. Además, observamos un fenómeno de sobrediferenciación en la gráfica de la segunda diferenciación, donde la autocorrelación ingresa rápidamente a la zona negativa.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterios-aic-bic-y-hqic",
    "href": "ts_python.html#criterios-aic-bic-y-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterios AIC, BIC y HQIC",
    "text": "Criterios AIC, BIC y HQIC\nLos criterios de información de Akaike (AIC), Bayesiano (BIC) y de Hannan-Quinn (HQIC) utilizan el método de estimación de máxima verosimilitud (log-verosimilitud) de los modelos como medida de ajuste. Estas medidas buscan valores bajos para indicar un mejor ajuste del modelo a los datos, empleando las siguientes fórmulas:\n\\[\n\\begin{align*}\n    \\text{AIC} &= 2k - 2 \\ln(L) \\\\\n    \\text{BIC} &= k \\ln(n) - 2 \\ln(L) \\\\\n    \\text{HQIC} &= 2k \\ln(\\ln(n)) - 2 \\ln(L).\n\\end{align*}\n\\]\ndonde \\(k\\) representa el número de parámetros en el modelo estadístico, \\(L\\) el valor de la función de máxima verosimilitud del modelo estimado, y \\(n\\) el tamaño de la muestra.\nEs importante destacar que, aunque aumentar el número de parámetros puede aumentar el valor de la verosimilitud, esto puede conducir a problemas de sobreajuste en el modelo. Para abordar este problema, los criterios mencionados anteriormente introducen un término de penalización basado en el número de parámetros. El término de penalización es mayor en el BIC que en el AIC para muestras superiores a 7. Por su parte, el HQIC busca equilibrar esta penalización, situándose entre el AIC y el BIC. La elección del criterio a utilizar dependerá del objetivo principal de la investigación.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "href": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "División de datos para entrenamiento del modelo",
    "text": "División de datos para entrenamiento del modelo\nAhora procederemos a definir nuestro conjunto de datos para entrenar el modelo. Definiremos inicialmente nuestro conjunto de prueba con un horizonte de 28 días pues, este abarcará también los casos en que queramos realizar pronósticos con horizontes de 7, 14 y 21 días.\n\nn: int = len(stock_data.Close)\nn_test: int = 28\n\ntrain_size: int = n - n_test\n\ntrain: pd.DataFrame = stock_data.Close[:train_size]\ndates_train: pd.DataFrame = stock_data.Date[:train_size]\n\ntest28: pd.DataFrame = stock_data.Close[train_size:train_size + n_test]\ndates_test28: pd.DataFrame = stock_data.Date[train_size:train_size + n_test]",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-arima",
    "href": "ts_python.html#modelo-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ARIMA",
    "text": "Modelo ARIMA\nUtilizaremos el modelo ARIMA a través de la biblioteca statsmodels para explorar diferentes combinaciones de órdenes \\(p, d, q\\). Utilizaremos el método de máxima verosimilitud (method = 'mle') para calcular la verosimilitud exacta mediante el filtro de Kalman.\nComencemos creando una función que tome un dataframe de entrenamiento y devuelva el mejor conjunto de órdenes \\(p, d, q\\) asociados al criterio AIC de bondad de ajuste, junto con los valores de AIC y BIC, y el mejor modelo encontrado.\nRecordemos que, el valor \\(d\\) corresponde al número de diferenciaciones que podemos realizar a nuestra serie de tiempo. Teniendo en cuenta las gráficas de autocorrelación y la prueba de Dickey-Fuller realizada, podemos saber que el máximo valor que puede tomar \\(d\\) será de 1 diferenciación a la serie de tiempo.\n\ndef arima_model(train: pd.DataFrame, criteria: str) -&gt; tuple:\n    best_order: tuple = None\n    best_mdl: ARIMAResults = None\n\n    p_rng: range = range(2)\n    d_rng: range = range(2)\n    q_rng: range = range(3)\n\n\n    print(f'Minimizing {criteria.upper()} to find best model')\n    if criteria == 'aic':\n        best_aic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_aic: float = tmp_mdl.aic\n                        if tmp_aic &lt; best_aic:\n                            best_aic = tmp_aic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: AIC = {best_aic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_aic, best_mdl\n    elif criteria == 'bic':\n        best_bic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_bic: float = tmp_mdl.bic\n                        if tmp_bic &lt; best_bic:\n                            best_bic = tmp_bic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: BIC = {best_bic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_bic, best_mdl\n    else:\n        best_hqic: float = np.inf\n\n        for p in p_rng:\n            for d in d_rng:\n                for q in q_rng:\n                    begin = time.time()\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_hqic: float = tmp_mdl.hqic\n                        if tmp_hqic &lt; best_hqic:\n                            best_hqic = tmp_hqic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n                            end = time.time()\n                            print(f'ARIMA{best_order}: HQIC = {best_hqic:.3f}, Time: {end - begin:.2f} sec')\n                    except:\n                        continue \n        return best_order, best_hqic, best_mdl\n\nA continuación, evaluemos nuestro conjunto de entrenamiento para obtener el mejor orden, AIC y el mejor modelo ARIMA. Antes de proceder, conviene crear una función que busque el modelo en una ruta especificada y, en caso de existir, lo cargue, o en su defecto, lo guarde si no se encuentra disponible en esa ubicación.\n\ndef get_model(filename: str, train: pd.DataFrame, criteria: str) -&gt; tuple:\n    if os.path.isfile(filename):\n        with open(filename, 'rb') as f:\n            return pickle.load(f)\n    else:\n        order, c, model = arima_model(train, criteria)\n\n        model_data = (order, c, model)\n        with open(filename, 'wb') as f:\n            pickle.dump(model_data, f)\n\n        return order, c, model\n\n\norder: tuple\naic: float\nmodel: ARIMAResults\n\norder, aic, model = get_model(\"arima_model_aic.pkl\", train, 'aic')\n\nMinimizing AIC to find best model\nARIMA(0, 0, 0): AIC = 102326.357, Time: 0.07 sec\nARIMA(0, 0, 1): AIC = 72917.284, Time: 17.50 sec\nARIMA(0, 0, 2): AIC = 69222.226, Time: 15.25 sec\nARIMA(0, 1, 0): AIC = 56402.068, Time: 0.03 sec\nARIMA(0, 1, 1): AIC = 56400.839, Time: 0.35 sec\nARIMA(1, 1, 0): AIC = 56400.701, Time: 0.06 sec\nARIMA(1, 1, 2): AIC = 56395.905, Time: 8.41 sec\n\n\n\n\nBest model: ARIMA(1, 1, 2) | Best AIC: 56395.905\nTotal fit time: 48.02 sec",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#auto-arima",
    "href": "ts_python.html#auto-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Auto ARIMA",
    "text": "Auto ARIMA\nTambién tenemos la opción de obtener el modelo ARIMA utilizando una función llamada auto_arima. Sin embargo, esta función genera un simple random walk \\(x_{t} = x_{t - 1} + \\omega_{t}\\), que predice puramente basado en el valor temporal anterior \\(t - 1\\).\n\nauto_arima: pm.arima.auto_arima = pm.arima.auto_arima(\n    train, start_p=1, start_q=1,\n    test='adf',\n    max_p=3, max_q=3,\n    m=1,\n    d=None,\n    seasonal=False,\n    start_P=0, \n    D=0, \n    trace=True,\n    error_action='ignore',  \n    suppress_warnings=True, \n    stepwise=True\n)\n\nPerforming stepwise search to minimize aic\n ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=56402.531, Time=4.81 sec\n ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=56402.437, Time=0.07 sec\n ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=56400.953, Time=0.09 sec\n ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=56401.094, Time=5.04 sec\n ARIMA(0,1,0)(0,0,0)[0]             : AIC=56402.068, Time=0.05 sec\n ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=56401.721, Time=0.66 sec\n ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=56400.991, Time=28.63 sec\n ARIMA(1,1,0)(0,0,0)[0]             : AIC=56400.701, Time=0.04 sec\n ARIMA(2,1,0)(0,0,0)[0]             : AIC=56401.395, Time=1.75 sec\n ARIMA(1,1,1)(0,0,0)[0]             : AIC=56402.204, Time=12.64 sec\n ARIMA(0,1,1)(0,0,0)[0]             : AIC=56400.839, Time=0.67 sec\n ARIMA(2,1,1)(0,0,0)[0]             : AIC=56396.383, Time=9.18 sec\n ARIMA(3,1,1)(0,0,0)[0]             : AIC=56396.769, Time=32.07 sec\n ARIMA(2,1,2)(0,0,0)[0]             : AIC=inf, Time=56.04 sec\n ARIMA(1,1,2)(0,0,0)[0]             : AIC=56395.905, Time=7.06 sec\n ARIMA(0,1,2)(0,0,0)[0]             : AIC=56401.227, Time=1.47 sec\n ARIMA(1,1,3)(0,0,0)[0]             : AIC=56396.378, Time=13.79 sec\n ARIMA(0,1,3)(0,0,0)[0]             : AIC=56399.762, Time=7.93 sec\n ARIMA(2,1,3)(0,0,0)[0]             : AIC=56399.224, Time=31.65 sec\n ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=56396.596, Time=28.63 sec\n\nBest model:  ARIMA(1,1,2)(0,0,0)[0]          \nTotal fit time: 242.330 seconds\n\n\nCon esto, podemos notar que el valor del AIC obtenido es más bajo en el modelo obtenido mediante la función arima_model que en el modelo generado por la función auto_arima. Esta discrepancia se debe a que la función auto_arima se basa únicamente en el dato anterior para realizar predicciones, lo cual no se ajusta adecuadamente al análisis que deseamos realizar. La naturaleza cambiante de los mercados financieros, especialmente en el caso de activos como Bitcoin, que son altamente volátiles, requiere un enfoque más sofisticado que considere la evolución histórica para comprender mejor sus comportamientos.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-ajustado",
    "href": "ts_python.html#modelo-ajustado",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ajustado",
    "text": "Modelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de Akaike. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\ndef fitted_model(train: pd.DataFrame, order: tuple) -&gt; list:\n    model_arima: ARIMA = ARIMA(train, order=order)\n    model_fit: ARIMAResults = model_arima.fit()\n\n    fig: plt.Figure\n    ax: np.ndarray\n\n    plt.rcParams.update({'figure.figsize': (9,9)})\n\n    fig, ax = plt.subplots();\n    plot_predict(model_fit, 1, ax=ax);\n    plt.show();\n\n    return model_arima, model_fit\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\nDespués de obtener el modelo ajustado y visualizar la gráfica resultante, podemos observar que el rango del intervalo de confianza para las predicciones es estrecho. Esto sugiere que los pronósticos que estamos obteniendo podrían estar ajustándose correctamente a partir de los datos de entrenamiento.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "href": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Pronóstico continuo (Rolling Forecast)",
    "text": "Pronóstico continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\ndef arima_rolling(history: list, test: list, best_order: tuple) -&gt; list:\n    predictions: list = []\n\n    for t in range(len(test)):\n        model: ARIMA = ARIMA(history, order=best_order)\n        model_fit: ARIMAResults = model.fit()\n        output: tuple = model_fit.forecast()\n        yhat: float = output[0]\n        predictions.append(yhat)\n        obs: float = test[t]\n        history.append(obs)\n        print('predicted=%f, expected=%f' % (yhat, obs))\n\n    return predictions\n\ntrain_list: list = train.tolist()\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\ntest7: pd.DataFrame = stock_data.Close[train_size:train_size + 7]\ndates_test7: pd.DataFrame = stock_data.Date[train_size:train_size + 7]\n\ntest7: list = test7.tolist()\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\ntest14: pd.DataFrame = stock_data.Close[train_size:train_size + 14]\ndates_test14: pd.DataFrame = stock_data.Date[train_size:train_size + 14]\n\ntest14: list = test14.tolist()\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\ntest21: pd.DataFrame = stock_data.Close[train_size:train_size + 21]\ndates_test21: pd.DataFrame = stock_data.Date[train_size:train_size + 21]\n\ntest21: list = test21.tolist()\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\ntest28: list = test28.tolist()\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=62061.895128, expected=67913.671875\npredicted=67543.583003, expected=65491.390625\npredicted=65617.962481, expected=63778.761719\npredicted=63827.031741, expected=64062.203125\npredicted=63953.197913, expected=67234.171875\npredicted=67000.837453, expected=69958.812500\npredicted=69912.449996, expected=69987.835938\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=70099.062541, expected=67913.671875\npredicted=68121.268978, expected=65491.390625\npredicted=65673.922849, expected=63778.761719\npredicted=63860.940072, expected=64062.203125\npredicted=64042.321557, expected=67234.171875\npredicted=67132.316876, expected=69958.812500\npredicted=69915.270838, expected=69987.835938\npredicted=70075.230679, expected=69455.343750\npredicted=69565.806971, expected=70744.953125\npredicted=70781.195373, expected=69892.828125\npredicted=70015.961974, expected=69645.304688\npredicted=69736.097246, expected=71333.648438\npredicted=71346.181357, expected=69702.148438\npredicted=69852.378153, expected=65446.972656\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=65618.583610, expected=67913.671875\npredicted=67837.288297, expected=65491.390625\npredicted=65562.948111, expected=63778.761719\npredicted=63785.400704, expected=64062.203125\npredicted=63956.590833, expected=67234.171875\npredicted=67097.724028, expected=69958.812500\npredicted=69884.467129, expected=69987.835938\npredicted=70041.805917, expected=69455.343750\npredicted=69533.794209, expected=70744.953125\npredicted=70732.579624, expected=69892.828125\npredicted=69985.388050, expected=69645.304688\npredicted=69708.213788, expected=71333.648438\npredicted=71319.233696, expected=69702.148438\npredicted=69824.909341, expected=65446.972656\npredicted=65644.821635, expected=65980.812500\npredicted=65966.309575, expected=68508.843750\npredicted=68420.036194, expected=67837.640625\npredicted=67885.662403, expected=68896.109375\npredicted=68879.449663, expected=69362.554688\npredicted=69374.521537, expected=71631.359375\npredicted=71583.371847, expected=69139.015625\n\nARIMA Rolling - Horizonte de 28 días\npredicted=69287.033459, expected=67913.671875\npredicted=67994.333491, expected=65491.390625\npredicted=65597.118347, expected=63778.761719\npredicted=63832.588762, expected=64062.203125\npredicted=64029.900746, expected=67234.171875\npredicted=67106.747346, expected=69958.812500\npredicted=69883.610835, expected=69987.835938\npredicted=70018.542161, expected=69455.343750\npredicted=69506.265640, expected=70744.953125\npredicted=70735.554824, expected=69892.828125\npredicted=69956.800223, expected=69645.304688\npredicted=69685.024265, expected=71333.648438\npredicted=71309.180755, expected=69702.148438\npredicted=69793.458480, expected=65446.972656\npredicted=65601.354080, expected=65980.812500\npredicted=65960.437174, expected=68508.843750\npredicted=68385.869406, expected=67837.640625\npredicted=67865.086195, expected=68896.109375\npredicted=68863.541074, expected=69362.554688\npredicted=69335.889689, expected=71631.359375\npredicted=71583.264500, expected=69139.015625\npredicted=69214.227780, expected=70587.882812\npredicted=70560.793444, expected=70060.609375\npredicted=70104.859968, expected=67195.867188\npredicted=67363.595050, expected=63821.472656\npredicted=63922.454408, expected=65738.726562\npredicted=65699.376228, expected=63426.210938\npredicted=63489.701088, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Observamos cómo los pronósticos se ajustan a las respuestas esperadas a medida que el “tiempo” transcurre. Esto se evidencia porque al inicio, los pronósticos están un poco alejados de la realidad, pero con el tiempo, la línea de pronóstico se ajusta más al comportamiento del conjunto de prueba. Este ajuste ocurre porque en cada predicción que realizamos, estamos tomando en cuenta el valor de prueba anterior como dato histórico. Esto permite que la serie de tiempo se adapte a los cambios que ocurren a lo largo de los días.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#análsis-de-residuales",
    "href": "ts_python.html#análsis-de-residuales",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Análsis de residuales",
    "text": "Análsis de residuales\n\nTest de normalidad\nRealizar un test de normalidad es importante porque nos ayuda a determinar la distribución de nuestros datos. Con ello, podemos evaluar si nuestros datos se ajustan lo suficientemente bien a una distribución normal para utilizar métodos estadísticos paramétricos de manera adecuada. Si los datos no son normales, es posible que necesitemos aplicar métodos estadísticos no paramétricos o considerar transformaciones de datos para cumplir con los supuestos necesarios para nuestros análisis.\nPara esta prueba, utilizaremos el test de normalidad de Shapiro-Wilks, el cual sirve para “medir el grado de ajuste a una recta de las observaciones de la muestra representadas en un gráfico de probabilidad normal, de forma que se rechazará la hipótesis nula de normalidad cuando el ajuste sea malo, situación que se corresponde con valores pequeños del estadístico de contraste. Este contraste es el más adecuado cuando el tamaño de muestra es pequeño (no superior a 3000) y tampoco requiere que los parámetros de la distribución estén especificados” (Álvarez, González, y Mangin 2006). El estadístico de prueba se calcula como:\n\\[\n    W = \\frac{\\left(\\sum_{i = 1}^n a_i x_{(i)}\\right)^2}{\\sum_{i = 1}^n \\left(x_i - \\bar{x}\\right)^2},\n\\]\ndonde \\(x_{(i)}\\) son los datos de la muestra en la posición \\(i\\), \\(\\bar{x}\\) representa la media de los datos y \\(a_i\\) se calcula de la siguiente manera:\n\\[\n    \\left(a_1, a_2, \\dots, a_n\\right) = \\frac{m^\\top V^{-1}}{\\left(m^\\top V^{-1} V^{-1} m\\right)},\n\\]\nsiendo \\(m\\) los valores medios del estadístico ordenado de distribuciones normales y \\(V\\) la matriz varianzas-covarianzas de ese estadístico (Shapiro y Wilk 1965). La prueba de hipótesis se plantea como:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{Los datos siguen una distribución normal}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{Los datos no siguen una distribución normal}\n\\end{gather}\n\\]\nPara no rechazar la hipótesis nula, el p-valor debe ser mayor que \\(0.05\\) o el estadístico \\(W\\) no debe ser demasiado pequeño.\nAhora, para realizar esta prueba de normalidad de nuestros residuales, crearemos una función llamada normality que nos permitirá realizar estas pruebas a lo largo de este análisis.\n\ndef normality(model: ARIMAResults) -&gt; None:\n    qq: Figure\n    stat: float\n    pvalue: float\n\n    qq = model.plot_diagnostics(figsize=(9,9))\n\n    stat, pvalue = shapiro(model.resid)\n\n    print('Shapiro-Wilks Test')\n    print('Alternative Hipothesis: Data is not distributed normally')\n    print(f'Statistic = {stat:.3f}')\n    print(f'P-Value = {pvalue}')\n    if(pvalue &lt; 0.05):\n        print('Se rechaza la hipótesis nula, los residuales no siguen una distribución normal.')\n    else:\n        print('No se rechaza la hipótesis nula, los residuales siguen una distribución normal.')\n\nEvualuemos nuestro modelo en la función creada\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.7406507906788266e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de Independencia\nEl test de independencia es crucial en estadística para determinar si existe una asociación significativa entre variables en una población. Uno de los principales supuestos de los modelos es que no existe autocorrelación entre los residuales, es decir, son independendientes. La autocorrelación es la similitud de una serie de tiempo en intervalos de tiempo sucesivos. Puede dar lugar a subestimaciones del error estándar y hacer que piense que los predictores son significativos cuando no lo son.\nUna forma de determinar si se cumple este supuesto es realizar una prueba de Durbin-Watson, que se utiliza para detectar la presencia de autocorrelación en los residuos. La prueba de Durbin-Watson utiliza la siguiente prueba de hipótesis:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{No existe correlación entre los residuales}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{Los residuos están correlacionados}\n\\end{gather}\n\\]\nEl estadístico de prueba para la prueba de Durbin-Watson, normalmente denotado \\(d\\), se calcula de la siguiente manera:\n\\[\n    d = \\frac{\\sum_{i = 1}^T \\left(e_{t} - e_{t - 1}\\right)^2}{\\sum_{i = 1}^T e_t^2},\n\\]\ndonde \\(T\\) es el número de observaciones y \\(e_t\\) el t-ésimo residual del modelo.\nEl estadístico de prueba siempre varía de 0 a 4, donde:\n\n\\(d = 2\\), indica que no hay autocorrelación.\n\\(d &lt; 2\\), indica que existe correlación serial positiva.\n\\(d &gt; 2\\), indica que existe correlación serial negativa.\n\nEn general, si d es menor que \\(1.5\\) o mayor que \\(2.5\\), existe un problema de autocorrelación potencialmente grave. De lo contrario, si \\(d\\) está entre \\(1.5\\) y \\(2.5\\), es probable que la autocorrelación no sea motivo de preocupación (Bartels y Goodhew 1981).\nAhora, para realizar esta prueba de independencia de nuestros residuales, crearemos una función llamada autocorrelation que nos permitirá realizar estas pruebas a lo largo de este análisis.\n\ndef autocorrelation(model: ARIMAResults) -&gt; None: \n    dw = durbin_watson(model.resid)\n\n    print('Durbin-Watson Test')\n    print('Alternative Hipothesis: Residuals are correlated')\n    print(f'Statistic d = {dw:.3f}')\n    if(dw &lt; 1.5 or dw &gt; 2.5):\n        print('Se rechaza la hipótesis nula, los residuales están correlacionados.')\n    else:\n        print('No se rechaza la hipótesis nula, no existe correlación entre los residuales.')\n\nEvaluamos nuestro modelo:\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 1.984\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-bic",
    "href": "ts_python.html#criterio-bic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio BIC",
    "text": "Criterio BIC\n\norder: tuple\nbic: float\nmodel: ARIMAResults\n\norder, bic, model = get_model(\"arima_model_bic.pkl\", train, 'bic')\n\nMinimizing BIC to find best model\nARIMA(0, 0, 0): BIC = 102338.662, Time: 0.07 sec\nARIMA(0, 0, 1): BIC = 72935.742, Time: 18.58 sec\nARIMA(0, 0, 2): BIC = 69246.836, Time: 67.70 sec\nARIMA(0, 1, 0): BIC = 56408.220, Time: 0.03 sec\n\n\n\n\nBest model: ARIMA(0, 1, 0) | Best BIC: 56408.2204598203\nTotal fit time: 172.59 sec\n\n\nBasándonos en el resultado obtenido para el mejor orden y el valor del mejor BIC, podemos afirmar que el modelo que mejor se ajusta, de los realizados hasta ahora, sería el obtenido mediante el criterio de Akaike, Orden: (1, 1, 2) y AIC: 56395.90534927711.\n\nModelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de inferencia Bayesiana. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\n Al igual que para el modelo ajustado mediante el mejor orden obtenido por el criterio de Akaike, podemos observar que el rango del intervalo de confianza correspondiente a las predicciones es pequeño, lo que nos permite pensar que las predicciones se ajustan de manera correcta a los datos de entrenamiento.\n\n\nPronóstico Continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=63811.863281, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=69987.835938, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=65446.972656, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\n\nARIMA Rolling - Horizonte de 28 días\npredicted=69139.015625, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=63426.210938\npredicted=63426.210938, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Los resultados obtenidos de estos pronósticos son bastante similares a los que observamos anteriormente mediante el criterio AIC. Esto nos podría permitir afirmar que entre el criterio AIC y BIC no hay mucha diferencia en los resultados obtenidos para nuestra serie de tiempo.\n\n\nModelo ARIMA sin usar rolling\nRepita el paso 2 ahora sin utilizar rolling. Esto es, realice el pronóstico solo utilizando forecast() para los diferentes horizontes de predicción 7, 14, 21 y 28 días.\nPara realizar el pronóstico sin usar rolling lo único que debemos modificar de nuestra función anterior es eliminar la línea de código donde estamos guardando en el conjunto de datos history el valor observado del test. Es decir, este conjunto en nuestra nueva función ya no variará sino que será estático para cada una de las predicciones realizadas.\n\nprint('ARIMA sin Rolling - Horizonte de 7 días.')\nyhat7_nor: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 14 días.')\nyhat14_nor: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 21 días.')\nyhat21_nor: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 28 días')\nyhat28_nor: list = arima_rolling(train_list, test28, order)\n\nARIMA sin Rolling - Horizonte de 7 días.\npredicted=63811.863281, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\n\nARIMA sin Rolling - Horizonte de 14 días.\npredicted=69987.835938, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\n\nARIMA sin Rolling - Horizonte de 21 días.\npredicted=65446.972656, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\n\nARIMA sin Rolling - Horizonte de 28 días\npredicted=69139.015625, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=63426.210938\npredicted=63426.210938, expected=63811.863281\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días sin usar rolling\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarmente, en el caso del criterio AIC, observamos que al inicio de las líneas de pronóstico, los resultados son similares a los obtenidos al usar rolling para realizar nuestras predicciones. Esto se debe a que, como se mencionó anteriormente, en el método rolling forecasting también utilizamos los datos de test como datos históricos. Sin embargo, también podemos notar que a medida que transcurren los días, la gráfica sigue un comportamiento similar. Esto indica que el modelo ajustado con rolling forecasting no está explicando mejor los datos que cuando no usamos esta técnica de media móvil. Ahora que examinemos las métricas obtenidas de nuestros modelos, podremos confirmar si los resultados también son similares.\n\n\nComparación entre modelos\nPara obtener las métricas de los modelos generados usaremos la función forest_accuracy creada anteriormente.\nObtengamos inicialmente las métricas para el modelo usando rolling\n\naccuracy7: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7), \"7 días\")\naccuracy14: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14), \"14 días\")\naccuracy21: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21), \"21 días\")\naccuracy28: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28), \"28 días\")\n\nAhora, obtengamos las métricas para el modelo obtenido sin usar rolling\n\naccuracy7_nor: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7_nor), \"7 días no rolling\")\naccuracy14_nor: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14_nor), \"14 días no rolling\")\naccuracy21_nor: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21_nor), \"21 días no rolling\")\naccuracy28_nor: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28_nor), \"28 días no rolling\")\n\naccuracy: pd.DataFrame = pd.concat([accuracy7, accuracy14, accuracy21, accuracy28, accuracy7_nor, accuracy14_nor, accuracy21_nor, accuracy28_nor])\n\naccuracy\n\n\n\n\n\n\n\n\n\nMAE\nMSE\nMAPE\nRMSE\nR2\n\n\n\n\n7 días\n2063.684710\n6.170230e+06\n0.031571\n2483.994814\n-0.085016\n\n\n14 días\n1636.779855\n4.072984e+06\n0.024020\n2018.163546\n0.320933\n\n\n21 días\n1586.980469\n3.744183e+06\n0.023356\n1934.989183\n0.236080\n\n\n28 días\n1604.140485\n3.756698e+06\n0.023619\n1938.220342\n0.409721\n\n\n7 días no rolling\n2063.684710\n6.170230e+06\n0.031571\n2483.994814\n-0.085016\n\n\n14 días no rolling\n1636.779855\n4.072984e+06\n0.024020\n2018.163546\n0.320933\n\n\n21 días no rolling\n1586.980469\n3.744183e+06\n0.023356\n1934.989183\n0.236080\n\n\n28 días no rolling\n1604.140485\n3.756698e+06\n0.023619\n1938.220342\n0.409721\n\n\n\n\n\n\n\n\nLos resultados obtenidos mediante el criterio de Inferencia Bayesiana (BIC) muestran una consistencia notable con los resultados anteriores obtenidos a través del criterio de Akaike (AIC). Ambos conjuntos de métricas presentan patrones similares en cuanto a la comparación entre modelos con y sin el uso de rolling. En general, los modelos con rolling tienden a ofrecer un rendimiento superior en todas las métricas evaluadas en comparación con los modelos sin rolling. Esto sugiere que, independientemente del criterio de selección del modelo utilizado, el enfoque de rolling parece ser beneficioso para la precisión de la predicción en este contexto particular. Además, se destaca que los valores de MAE, MSE, MAPE, RMSE y R2 son consistentes entre los modelos con y sin rolling para cada intervalo de predicción, lo que indica que el enfoque de rolling no solo mejora la precisión, sino también la estabilidad de los modelos de predicción.\n\nplt.rcParams.update({'figure.figsize': (9, 16)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(4)\n\nsns.scatterplot(x=test7, y=yhat7, ax=axes[0], color='#5a189a', label='Real vs Estimado')\naxes[0].plot(test7, test7, color='#c77dff', label='Correlación')\naxes[0].set_title('Horizonte 7 días', fontsize=12)\n\nsns.scatterplot(x=test14, y=yhat14, ax=axes[1], color='#5a189a', label='Real vs Estimado')\naxes[1].plot(test14, test14, color='#c77dff', label='Correlación')\naxes[1].set_title('Horizonte 14 días', fontsize=12)\n\nsns.scatterplot(x=test21, y=yhat21, ax=axes[2], color='#5a189a', label='Real vs Estimado')\naxes[2].plot(test21, test21, color='#c77dff', label='Correlación')\naxes[2].set_title('Horizonte 21 días', fontsize=12)\n\nsns.scatterplot(x=test28, y=yhat28, ax=axes[3], color='#5a189a', label='Real vs Estimado')\naxes[3].plot(test28, test28, color='#c77dff', label='Correlación')\naxes[3].set_title('Horizonte 28 días', fontsize=12)\n\nText(0.5, 1.0, 'Horizonte 28 días')\n\n\n\n\n\n\n\n\n\n Nuevamente, podemos observar que a medida que las ventanas de predicción aumentan, los valores predichos se ajustan más a la línea del test. Lo que reafirma la idea de que la técnica de las predicciones utilizando la media móvil (rolling) es efectiva para este tipo de modelos.\n\n\nAnálisis de los residuales\n\nTest de normalidad\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.672904862089655e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de independencia\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 2.048\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-hqic",
    "href": "ts_python.html#criterio-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio HQIC",
    "text": "Criterio HQIC\n\norder: tuple\nhqic: float\nmodel: ARIMAResults\n\norder, hqic, model = get_model(\"arima_model_hqic.pkl\", train, 'hqic')\n\nMinimizing HQIC to find best model\nARIMA(0, 0, 0): HQIC = 102330.751, Time: 0.08 sec\nARIMA(0, 0, 1): HQIC = 72923.874, Time: 44.34 sec\nARIMA(0, 0, 2): HQIC = 69231.012, Time: 61.35 sec\nARIMA(0, 1, 0): HQIC = 56404.265, Time: 0.06 sec\n\n\n\n\nBest model: ARIMA(0, 1, 0) | Best HQIC: 56404.26483697662\nTotal fit time: 112.02 sec\n\n\nNotemos que el orden obtenido es el mismo que el obtenido para el criterio BIC. Por tanto, los resultados que se obtendrían si siguieramos con el análisis planteado anteriormente serían iguales.\n\nAnálisis de residuales\n\nTest de normalidad\n\nnormality(model)\n\nShapiro-Wilks Test\nAlternative Hipothesis: Data is not distributed normally\nStatistic = 0.703\nP-Value = 1.672904862089655e-61\nSe rechaza la hipótesis nula, los residuales no siguen una distribución normal.\n\n\n\n\n\n\n\n\n\n\n\nTest de independencia\n\nautocorrelation(model)\n\nDurbin-Watson Test\nAlternative Hipothesis: Residuals are correlated\nStatistic d = 2.048\nNo se rechaza la hipótesis nula, no existe correlación entre los residuales.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Series de tiempo",
    "section": "",
    "text": "Una serie temporal es una realización parcial de un proceso estocástico de parámetro tiempo discreto, donde los elementos de \\(I\\) están ordenados y corresponden a instantes equidistantes del tiempo. Estos procesos estocásticos son colecciones o familias de variables aleatorias \\(\\{X_{t}\\}_{t\\in I}\\) ordenadas según el subíndice \\(t\\) que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si \\(I\\) es discreto, el proceso es en tiempo discreto. Si \\(I\\) es continuo, el proceso es en tiempo continuo. Entre las series de tiempo, existen modelos estadísticos que definen el proceso de cualquier conjunto de hipótesis bien definidas sobre las propeidades estadísticas de dicho proceso estocástico.\nUno de los modelos más utilizados a la hora de realizar pronósticos de series de tiempo es el modelo ARIMA. Estos modelos ARIMA (Autorregresivos Integrados de Media Móvil) aproximan los valores futuros de una serie temporal como una función lineal de observaciones pasadas y términos de ruido blanco. Una serie de tiempo \\(y_t\\) se llama un proceso de media móvil integrada autorregresiva (ARIMA) de órdenes \\(p, d, q\\), denotado ARIMA(\\(p, d, q\\)) si su diferencia \\(d\\) da lugar a un proceso estacionario ARMA(\\(p, q\\)). Por lo tanto, un ARIMA(\\(p, d, q\\)) puede escribirse como\n\\[\n    \\Phi(B)(1 - B)^{d} y_{t} = \\delta + \\Theta(B) \\varepsilon_{t}\n\\]\ndonde\n\\[\n    \\Phi(B) = 1 - \\sum_{i = 1}^{p} \\phi_{i} B^{i} \\quad \\text{y} \\quad \\Theta(B) = 1 - \\sum_{i = 1}^{q} \\theta_{i} B^{i},\n\\]\nson los términos del operador back-shit en los AR(\\(p\\)) y MA(\\(q\\)) definidos como \\(\\Phi(B) y_{t} = \\delta + \\varepsilon_{t}\\) y \\(y_{t} = \\mu + \\Theta(B) \\varepsilon_{t}\\) con \\(\\delta = \\mu - \\phi \\mu\\), donde \\(\\mu\\) es la media y \\(\\varepsilon_{t}\\) el ruido blanco con \\(E(\\varepsilon_t) = 0\\) (Rubio 2024).\n\n\n\n\nReferencias\n\nRubio, Lihki. 2024. «Predicciones de series de tiempo con Python». 2024. https://lihkir.github.io/DataVizPythonRUninorte/predictive_model.html.",
    "crumbs": [
      "Introducción"
    ]
  }
]