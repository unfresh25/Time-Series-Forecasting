[
  {
    "objectID": "ts_python.html",
    "href": "ts_python.html",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "",
    "text": "Para este proyecto trabajaremos con las siguientes librerías:\n\nPandas\nPlotly\nMatplotlib\nSeaborn\nYfinance\nNumpy\nStatsmodel\n\nPueden instalarse utilizando el siguiente comando desde la terminal: pip install pandas yfinance plotly..., o bien, mediante el archivo requirements.txt utilizando pip install -r requirements.txt en la terminal.\nUna vez instaladas, podemos importarlas en nuestro entorno de trabajo de la siguiente manera:\n\nimport os\nimport pickle\n\nimport pandas as pd\nimport numpy as np\nfrom numpy import log\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\n\nimport yfinance as yf\n\nfrom datetime import datetime, timedelta\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_predict\nfrom statsmodels.tsa.arima.model import ARIMA, ARIMAResults\nfrom sklearn.metrics import r2_score\n\nimport pmdarima as pm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Series de tiempo",
    "section": "",
    "text": "Un proceso estocástico es una colección o familia de variables aleatorias \\(\\{X_{t}\\}_{t\\in I}\\) ordenadas según el subíndice \\(t\\) que en general se suele identificar con el tiempo. Llamamos trayectoria del proceso a una realización del proceso estocástico. Si \\(I\\) es discreto, el proceso es en tiempo discreto. Si \\(I\\) es continuo, el proceso es en tiempo continuo.",
    "crumbs": [
      "Introducción"
    ]
  },
  {
    "objectID": "ts_python.html#visualización",
    "href": "ts_python.html#visualización",
    "title": "Predicciones de Series de Tiempo - Stock BTC-USD",
    "section": "Visualización",
    "text": "Visualización\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=stock_data['Date'], y=stock_data['Close'], mode='lines'))\n\nfig.update_layout(\n    title='Gráfico de Línea de Datos de Acciones',\n    xaxis_title='Fecha',\n    yaxis_title='Precio de Cierre',\n    plot_bgcolor='rgba(0, 0, 0, 0.0)',\n    paper_bgcolor='rgba(0, 0, 0, 0.0)'\n)\n\nfig.show()",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#series-estacionarias",
    "href": "ts_python.html#series-estacionarias",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Series estacionarias",
    "text": "Series estacionarias\nPara determinar si nuestra serie de tiempo es estacionaria, recurrimos al conocido test estadístico de Dickey-Fuller. Este test plantea las siguientes hipótesis:\n\\[\n\\begin{gather}\n    \\text{H}_0: \\text{La serie de tiempo no es estacionaria}\\\\\n    \\text{v.s.}\\\\\n    \\text{H}_1: \\text{La serie de tiempo es estacionaria}\n\\end{gather}\n\\]\nEl objetivo es no rechazar la hipótesis nula. Por lo tanto, evaluamos el resultado del test mediante el siguiente código:\n\nresult: tuple = adfuller(stock_data.Close)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\n\nADF Statistic: -0.830330\np-value: 0.810050\n\n\nDado que (p-valor &gt; 0.05), no rechazamos la hipótesis nula, lo que indica que la serie de tiempo es estacionaria. Esta conclusión se refuerza al analizar gráficamente la autocorrelación, lo que también nos permite entender el orden de integración necesario para transformar la serie de no estacionaria a estacionaria.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#autocorrelación",
    "href": "ts_python.html#autocorrelación",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Autocorrelación",
    "text": "Autocorrelación\nExaminemos estas gráficas de autocorrelación para las diferentes diferenciaciones de nuestra serie de tiempo, utilizando un número de retrasos (lags) de 240:\n\nplt.rcParams.update({'figure.figsize': (9, 9)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(stock_data.Close); axes[0, 0].set_title('Original Series')\nplot_acf(stock_data.Close, ax=axes[0, 1], lags = 240);\n\naxes[1, 0].plot(stock_data.Close.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(stock_data.Close.diff().dropna(), ax=axes[1, 1], lags = 240);\n\naxes[2, 0].plot(stock_data.Close.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(stock_data.Close.diff().diff().dropna(), ax=axes[2, 1], lags = 240);\n\n\n\n\nAutocorrelación de la serie de tiempo original, diferenciada 1 vez y 2 veces.\n\n\n\n\n\nSe observa que la gráfica de autocorrelación de la serie de tiempo original muestra un decaimiento con tendencia lineal o geométrica, lo que indica una autocorrelación típica de una serie no estacionaria. Además, observamos un fenómeno de sobrediferenciación en la gráfica de la segunda diferenciación, donde la autocorrelación ingresa rápidamente a la zona negativa.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterios-aic-bic-y-hqic",
    "href": "ts_python.html#criterios-aic-bic-y-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterios AIC, BIC y HQIC",
    "text": "Criterios AIC, BIC y HQIC\nLos criterios de información de Akaike (AIC), Bayesiano (BIC) y de Hannan-Quinn (HQIC) utilizan el método de estimación de máxima verosimilitud (log-verosimilitud) de los modelos como medida de ajuste. Estas medidas buscan valores bajos para indicar un mejor ajuste del modelo a los datos, empleando las siguientes fórmulas:\n\\[\n\\begin{align*}\n    \\text{AIC} &= 2k - 2 \\ln(L) \\\\\n    \\text{BIC} &= k \\ln(n) - 2 \\ln(L) \\\\\n    \\text{HQIC} &= 2k \\ln(\\ln(n)) - 2 \\ln(L).\n\\end{align*}\n\\]\ndonde \\(k\\) representa el número de parámetros en el modelo estadístico, \\(L\\) el valor de la función de máxima verosimilitud del modelo estimado, y \\(n\\) el tamaño de la muestra.\nEs importante destacar que, aunque aumentar el número de parámetros puede aumentar el valor de la verosimilitud, esto puede conducir a problemas de sobreajuste en el modelo. Para abordar este problema, los criterios mencionados anteriormente introducen un término de penalización basado en el número de parámetros. El término de penalización es mayor en el BIC que en el AIC para muestras superiores a 7. Por su parte, el HQIC busca equilibrar esta penalización, situándose entre el AIC y el BIC. La elección del criterio a utilizar dependerá del objetivo principal de la investigación.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#split-de-datos-para-entrenar-el-modelo",
    "href": "ts_python.html#split-de-datos-para-entrenar-el-modelo",
    "title": "Predicciones de Series de Tiempo - Stock BTC-USD",
    "section": "Split de datos para entrenar el modelo",
    "text": "Split de datos para entrenar el modelo\nDefinamos ahora cuál será nuestro conjunto de datos para entrenar el modelo, donde usaremos un conjunto de test con 28 registros del total de datos.\n\nn = len(stock_data.Close)\nn_test = 28\n\ntrain_size = n - n_test\n\ntrain = stock_data.Close[:train_size]\ndates_train = stock_data.Date[:train_size]\n\ntest_4w = stock_data.Close[train_size:train_size + n_test] \ndates_4w = stock_data.Date[train_size:train_size + n_test] \n\nprint(\"train:\", train.shape)\nprint(\"test_4w:\", test_4w.shape)\n\ntrain: (3469,)\ntest_4w: (28,)\n\n\n\ntrain_df = stock_data[[\"Close\"]][:train_size]\ntest_4w_df = stock_data[[\"Close\"]][train_size:train_size + n_test] \n\ntest_4w_df.head()\n\n\n\n\n\n\n\n\n\nClose\n\n\n\n\n3469\n68390.625000\n\n\n3470\n67548.593750\n\n\n3471\n61912.773438\n\n\n3472\n67913.671875\n\n\n3473\n65491.390625",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "href": "ts_python.html#división-de-datos-para-entrenamiento-del-modelo",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "División de datos para entrenamiento del modelo",
    "text": "División de datos para entrenamiento del modelo\nAhora procederemos a definir nuestro conjunto de datos para entrenar el modelo. Definiremos inicialmente nuestro conjunto de prueba con un horizonte de 28 días pues, este abarcará también los casos en que queramos realizar pronósticos con horizontes de 7, 14 y 21 días.\n\nn: int = len(stock_data.Close)\nn_test: int = 28\n\ntrain_size: int = n - n_test\n\ntrain: pd.DataFrame = stock_data.Close[:train_size]\ndates_train: pd.DataFrame = stock_data.Date[:train_size]\n\ntest28: pd.DataFrame = stock_data.Close[train_size:train_size + n_test]\ndates_test28: pd.DataFrame = stock_data.Date[train_size:train_size + n_test]",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-arima-1",
    "href": "ts_python.html#modelo-arima-1",
    "title": "Predicciones de Series de Tiempo - Stock BTC-USD",
    "section": "Modelo ARIMA",
    "text": "Modelo ARIMA\nUtilizaremos el modelo ARIMA a través de la biblioteca statsmodels para explorar diferentes combinaciones de órdenes \\(p, d, q\\). Utilizaremos el método de máxima verosimilitud (method = 'mle') para calcular la verosimilitud exacta mediante el filtro de Kalman.\nComencemos creando una función que tome un dataframe de entrenamiento y devuelva el mejor conjunto de órdenes \\(p, d, q\\) asociados al criterio AIC de bondad de ajuste, junto con los valores de AIC y BIC, y el mejor modelo encontrado.\n\ndef arima_model_aic(train: pd.DataFrame) -&gt; tuple:\n    best_aic: float = np.inf\n\n    best_order: tuple = None\n    best_mdl = None\n\n    pq_rng: range = range(4)\n    d_rng: range = range(4)\n\n    print('Minimizing AIC to find best model')\n    print(f'Max value for p, d, q = {max(pq_rng)}')\n\n    for p in pq_rng:\n        for d in d_rng:\n            for q in pq_rng:\n                try:\n                    tmp_mdl: ARIMA = ARIMA(train, order = (p, d, q)).fit()\n                    tmp_aic: float = tmp_mdl.aic\n                    print(f'ARIMA({p},{d},{q}): AIC = {tmp_aic}')\n\n                    if tmp_aic &lt; best_aic:\n                        best_aic = tmp_aic\n                        best_order = (p, d, q)\n                        best_mdl = tmp_mdl\n                except:\n                    continue \n\n    print(f'Best model: ARIMA{best_order} | Best AIC: {best_aic}')\n\n    return best_order, best_aic, best_mdl\n\nA continuación, evaluemos nuestro conjunto de entrenamiento para obtener el mejor orden, AIC, BIC y el mejor modelo ARIMA encontrado para cada uno de los conjuntos generados de los horizontes.\n\nHorizonte de 7 días\n\norder7: tuple\naic7: float\nbic7: float\nmodel7: ARIMA\n\norder7, aic7, model7 = arima_model_aic(train7)\n\nMinimizing AIC to find best model\nMax value for p, d, q = 3\nARIMA(0,0,0): AIC = 103065.23032593372\nARIMA(0,0,1): AIC = 73471.1189862779\nARIMA(0,0,2): AIC = 69771.95975760574\nARIMA(0,0,3): AIC = 74725.59330961699\nARIMA(0,1,0): AIC = 56835.19841665262\nARIMA(0,1,1): AIC = 56830.41636501397\nARIMA(0,1,2): AIC = 56831.91417951282\nARIMA(0,1,3): AIC = 56827.624851330525\nARIMA(0,2,0): AIC = 59390.003524471314\nARIMA(0,2,1): AIC = 56827.51582784409\nARIMA(0,2,2): AIC = 56822.593827174154\nARIMA(0,2,3): AIC = 56824.12728043629\nARIMA(0,3,0): AIC = 63264.70883609384\nARIMA(0,3,1): AIC = 59383.10900854195\nARIMA(0,3,2): AIC = 56846.470076840895\nARIMA(0,3,3): AIC = 56879.64082952867\nARIMA(1,0,0): AIC = 56862.316817026585\nARIMA(1,0,1): AIC = 56857.57914093052\nARIMA(1,0,2): AIC = 56859.05646189591\nARIMA(1,0,3): AIC = 56854.68409791969\nARIMA(1,1,0): AIC = 56830.28546286028\nARIMA(1,1,1): AIC = 56832.231366669985\nARIMA(1,1,2): AIC = 56827.91645591565\nARIMA(1,1,3): AIC = 56826.23081939421\nARIMA(1,2,0): AIC = 58264.41161208074\nARIMA(1,2,1): AIC = 56822.48236587246\nARIMA(1,2,2): AIC = 56831.64588368728\nARIMA(1,2,3): AIC = 56824.03407386932\nARIMA(1,3,0): AIC = 61139.37642026362\nARIMA(1,3,1): AIC = 58258.28741872896\nARIMA(1,3,2): AIC = 56942.96830817289\nARIMA(1,3,3): AIC = 56837.13066494412\nARIMA(2,0,0): AIC = 56857.44718790011\nARIMA(2,0,1): AIC = 56865.92558498546\nARIMA(2,0,2): AIC = 56859.0541834731\nARIMA(2,0,3): AIC = 56855.20005442781\nARIMA(2,1,0): AIC = 56832.129667110465\nARIMA(2,1,1): AIC = 56826.90509080571\nARIMA(2,1,2): AIC = 56821.18799910612\nARIMA(2,1,3): AIC = 56823.1481158957\nARIMA(2,2,0): AIC = 57761.69168541728\nARIMA(2,2,1): AIC = 56824.340765851346\nARIMA(2,2,2): AIC = 56825.93922806251\nARIMA(2,2,3): AIC = 56838.51083367373\nARIMA(2,3,0): AIC = 60024.598136891786\nARIMA(2,3,1): AIC = 57755.984428590295\nARIMA(2,3,2): AIC = 57147.41536584422\nARIMA(2,3,3): AIC = 57124.00319521599\nARIMA(3,0,0): AIC = 56859.277454951676\nARIMA(3,0,1): AIC = 56858.54160888\nARIMA(3,0,2): AIC = 56860.832275633984\nARIMA(3,0,3): AIC = 56856.26390477907\nARIMA(3,1,0): AIC = 56828.26669671007\nARIMA(3,1,1): AIC = 56826.789462864894\nARIMA(3,1,2): AIC = 56823.13106429465\nARIMA(3,1,3): AIC = 56823.1680517087\nARIMA(3,2,0): AIC = 57516.26293762986\nARIMA(3,2,1): AIC = 56820.562619091914\nARIMA(3,2,2): AIC = 56819.11821417119\nARIMA(3,2,3): AIC = 56834.30073488029\nARIMA(3,3,0): AIC = 59354.27977823685\nARIMA(3,3,1): AIC = 57510.98798086177\nARIMA(3,3,2): AIC = 56855.0539521281\nARIMA(3,3,3): AIC = 56830.46116768995\nBest model: ARIMA(3, 2, 2) | Best AIC: 56819.11821417119\n\n\n\n\nHorizonte de 14 días\n\norder14: tuple\naic14: float\nbic14: float\nmodel14: ARIMA\n\norder14, aic14, model14 = arima_model_aic(train14)\n\nMinimizing AIC to find best model\nMax value for p, d, q = 3\nARIMA(0,0,0): AIC = 102794.64398140741\nARIMA(0,0,1): AIC = 73268.78165724041\nARIMA(0,0,2): AIC = 69577.88613071185\nARIMA(0,0,3): AIC = 68688.92780573995\nARIMA(0,1,0): AIC = 56685.75596916387\nARIMA(0,1,1): AIC = 56680.73238427953\nARIMA(0,1,2): AIC = 56681.49610687478\nARIMA(0,1,3): AIC = 56677.62906174173\nARIMA(0,2,0): AIC = 59237.28074159697\nARIMA(0,2,1): AIC = 56677.875112263646\nARIMA(0,2,2): AIC = 56672.75400251053\nARIMA(0,2,3): AIC = 56673.58032436404\nARIMA(0,3,0): AIC = 63111.19474757189\nARIMA(0,3,1): AIC = 59230.40938910653\nARIMA(0,3,2): AIC = 56787.59899367484\nARIMA(0,3,3): AIC = 57010.240952459535\nARIMA(1,0,0): AIC = 56713.03243692787\nARIMA(1,0,1): AIC = 56708.02934541742\nARIMA(1,0,2): AIC = 56708.761896170094\nARIMA(1,0,3): AIC = 56704.818773290805\nARIMA(1,1,0): AIC = 56680.49910865234\nARIMA(1,1,1): AIC = 56682.25816553463\nARIMA(1,1,2): AIC = 56677.02855205035\nARIMA(1,1,3): AIC = 56675.993243936166\nARIMA(1,2,0): AIC = 58095.66268548458\nARIMA(1,2,1): AIC = 56672.55147527098\nARIMA(1,2,2): AIC = 56681.75043415201\nARIMA(1,2,3): AIC = 56671.987426294814\nARIMA(1,3,0): AIC = 60961.69024364275\nARIMA(1,3,1): AIC = 58089.346989712416\nARIMA(1,3,2): AIC = 56910.18856324504\nARIMA(1,3,3): AIC = 56686.80453089608\nARIMA(2,0,0): AIC = 56707.91100386775\nARIMA(2,0,1): AIC = 56716.73860264469\nARIMA(2,0,2): AIC = 56707.84144076654\nARIMA(2,0,3): AIC = 56707.70134402205\nARIMA(2,1,0): AIC = 56681.85421604978\nARIMA(2,1,1): AIC = 56677.182558678134\nARIMA(2,1,2): AIC = 56664.47535819921\nARIMA(2,1,3): AIC = 56665.32381673116\nARIMA(2,2,0): AIC = 57603.17159813919\nARIMA(2,2,1): AIC = 56673.947628373986\nARIMA(2,2,2): AIC = 56673.70535790677\nARIMA(2,2,3): AIC = 56664.262025378965\nARIMA(2,3,0): AIC = 59853.53202655773\nARIMA(2,3,1): AIC = 57597.477156870315\nARIMA(2,3,2): AIC = 57003.99853090182\nARIMA(2,3,3): AIC = 56682.00580642203\nARIMA(3,0,0): AIC = 56709.21195961395\nARIMA(3,0,1): AIC = 56709.30788535757\nARIMA(3,0,2): AIC = 56711.551340660735\nARIMA(3,0,3): AIC = 56709.18424981784\nARIMA(3,1,0): AIC = 56678.12195306184\nARIMA(3,1,1): AIC = 56676.3917436137\nARIMA(3,1,2): AIC = 56665.21137927218\nARIMA(3,1,3): AIC = 56667.72284875529\nARIMA(3,2,0): AIC = 57362.878896845774\nARIMA(3,2,1): AIC = 56670.30674679193\nARIMA(3,2,2): AIC = 56668.56816367242\nARIMA(3,2,3): AIC = 56674.87027476396\nARIMA(3,3,0): AIC = 59195.852396519214\nARIMA(3,3,1): AIC = 57357.61398015669\nARIMA(3,3,2): AIC = 56751.53277360818\nARIMA(3,3,3): AIC = 56678.769910069444\nBest model: ARIMA(2, 2, 3) | Best AIC: 56664.262025378965\n\n\n\n\nHorizonte de 21 días\n\norder21: tuple\naic21: float\nbic21: float\nmodel21: ARIMA\n\norder21, aic21, model21 = arima_model_aic(train21)\n\nMinimizing AIC to find best model\nMax value for p, d, q = 3\nARIMA(0,0,0): AIC = 102517.29663759039\nARIMA(0,0,1): AIC = 73060.36096241034\nARIMA(0,0,2): AIC = 69373.48711698921\nARIMA(0,0,3): AIC = 73920.77741170308\nARIMA(0,1,0): AIC = 56559.810798806575\nARIMA(0,1,1): AIC = 56553.810230086645\nARIMA(0,1,2): AIC = 56554.42107402196\nARIMA(0,1,3): AIC = 56550.27670630773\nARIMA(0,2,0): AIC = 59111.35447783679\nARIMA(0,2,1): AIC = 56552.271376587814\nARIMA(0,2,2): AIC = 56546.097034002785\nARIMA(0,2,3): AIC = 56546.74832333718\nARIMA(0,3,0): AIC = 62979.529021012386\nARIMA(0,3,1): AIC = 59104.470881458576\nARIMA(0,3,2): AIC = 56577.23580758675\nARIMA(0,3,3): AIC = 56551.5710535875\nARIMA(1,0,0): AIC = 56586.793537087724\nARIMA(1,0,1): AIC = 56580.856603580614\nARIMA(1,0,2): AIC = 56581.43111418464\nARIMA(1,0,3): AIC = 56577.199855799976\nARIMA(1,1,0): AIC = 56553.53018374233\nARIMA(1,1,1): AIC = 56555.2593475533\nARIMA(1,1,2): AIC = 56548.97841832558\nARIMA(1,1,3): AIC = 56548.50755318375\nARIMA(1,2,0): AIC = 57963.70141845531\nARIMA(1,2,1): AIC = 56545.83182304674\nARIMA(1,2,2): AIC = 56556.39677698571\nARIMA(1,2,3): AIC = 56548.07850637991\nARIMA(1,3,0): AIC = 60821.206315640826\nARIMA(1,3,1): AIC = 57957.38701299001\nARIMA(1,3,2): AIC = 56570.11434127428\nARIMA(1,3,3): AIC = 56563.4718002175\nARIMA(2,0,0): AIC = 56580.61989030166\nARIMA(2,0,1): AIC = 56590.60713588353\nARIMA(2,0,2): AIC = 56575.51617539668\nARIMA(2,0,3): AIC = 56576.341536296226\nARIMA(2,1,0): AIC = 56554.83146972517\nARIMA(2,1,1): AIC = 56549.776710547565\nARIMA(2,1,2): AIC = 56536.65409127529\nARIMA(2,1,3): AIC = 56540.22693876425\nARIMA(2,2,0): AIC = 57471.40789034686\nARIMA(2,2,1): AIC = 56547.16568153259\nARIMA(2,2,2): AIC = 56549.31773634625\nARIMA(2,2,3): AIC = 56552.144387126544\nARIMA(2,3,0): AIC = 59710.69158179403\nARIMA(2,3,1): AIC = 57465.71714936218\nARIMA(2,3,2): AIC = 10.0\nARIMA(2,3,3): AIC = 56555.45418920509\nARIMA(3,0,0): AIC = 56581.84752928122\nARIMA(3,0,1): AIC = 56582.416644983605\nARIMA(3,0,2): AIC = 56567.848266320376\nARIMA(3,0,3): AIC = 56574.97670345566\nARIMA(3,1,0): AIC = 56550.8842742454\nARIMA(3,1,1): AIC = 56548.90912337574\nARIMA(3,1,2): AIC = 56537.370485033294\nARIMA(3,1,3): AIC = 56540.02933291713\nARIMA(3,2,0): AIC = 57227.928584496825\nARIMA(3,2,1): AIC = 56543.2905243188\nARIMA(3,2,2): AIC = 56541.385471426474\nARIMA(3,2,3): AIC = 56557.50807674843\nARIMA(3,3,0): AIC = 59046.393367306795\nARIMA(3,3,1): AIC = 57222.67385307297\nARIMA(3,3,2): AIC = 56570.1102149694\nARIMA(3,3,3): AIC = 56553.55914791256\nBest model: ARIMA(2, 3, 2) | Best AIC: 10.0\n\n\n\n\nHorizonte de 28 días\n\norder28: tuple\naic28: float\nbic28: float\nmodel28: ARIMA\n\norder28, aic28, model28 = arima_model_aic(train28)\n\nMinimizing AIC to find best model\nMax value for p, d, q = 3\nARIMA(0,0,0): AIC = 102250.46116459556\nARIMA(0,0,1): AIC = 72862.66890091416\nARIMA(0,0,2): AIC = 69170.88380814758\nARIMA(0,0,3): AIC = 67364.57008539305\nARIMA(0,1,0): AIC = 56322.59603613171\nARIMA(0,1,1): AIC = 56321.14676611517\nARIMA(0,1,2): AIC = 56320.53113659485\nARIMA(0,1,3): AIC = 56321.111366610625\nARIMA(0,2,0): AIC = 58814.50816368914\nARIMA(0,2,1): AIC = 56314.858883421985\nARIMA(0,2,2): AIC = 56311.441861533516\nARIMA(0,2,3): AIC = 56312.82599474146\nARIMA(0,3,0): AIC = 62652.18280241691\nARIMA(0,3,1): AIC = 58807.69520872164\nARIMA(0,3,2): AIC = 56320.402402917105\nARIMA(0,3,3): AIC = 56389.83963040368\nARIMA(1,0,0): AIC = 56349.72130999989\nARIMA(1,0,1): AIC = 56348.296742310646\nARIMA(1,0,2): AIC = 56347.60225649855\nARIMA(1,0,3): AIC = 56348.13570025299\nARIMA(1,1,0): AIC = 56320.95786771643\nARIMA(1,1,1): AIC = 56321.757059548865\nARIMA(1,1,2): AIC = 56316.92067951041\nARIMA(1,1,3): AIC = 56318.9054580669\nARIMA(1,2,0): AIC = 57684.16589978718\nARIMA(1,2,1): AIC = 56313.19148392884\nARIMA(1,2,2): AIC = 56315.90090206308\nARIMA(1,2,3): AIC = 56315.43498475067\nARIMA(1,3,0): AIC = 60484.74278975273\nARIMA(1,3,1): AIC = 57677.91343521657\nARIMA(1,3,2): AIC = 56380.28007596549\nARIMA(1,3,3): AIC = 56320.57533154243\nARIMA(2,0,0): AIC = 56348.19884976442\nARIMA(2,0,1): AIC = 56353.63901413143\nARIMA(2,0,2): AIC = 56342.81295386229\nARIMA(2,0,3): AIC = 56343.678277593266\nARIMA(2,1,0): AIC = 56320.62269203766\nARIMA(2,1,1): AIC = 56316.99543656583\nARIMA(2,1,2): AIC = 56317.554023426404\nARIMA(2,1,3): AIC = 56320.92819650621\nARIMA(2,2,0): AIC = 57251.148417358425\nARIMA(2,2,1): AIC = 56312.92726242329\nARIMA(2,2,2): AIC = 56316.88605697662\nARIMA(2,2,3): AIC = 56318.57561064775\nARIMA(2,3,0): AIC = 59460.199249841884\nARIMA(2,3,1): AIC = 57245.48126456319\nARIMA(2,3,2): AIC = 56626.22192936076\nARIMA(2,3,3): AIC = 56607.86982139759\nARIMA(3,0,0): AIC = 56347.69317531104\nARIMA(3,0,1): AIC = 56351.91904714153\nARIMA(3,0,2): AIC = 56351.929845148145\nARIMA(3,0,3): AIC = 56347.33334530685\nARIMA(3,1,0): AIC = 56321.012831864515\nARIMA(3,1,1): AIC = 56318.93522857431\nARIMA(3,1,2): AIC = 56319.24023269379\nARIMA(3,1,3): AIC = 56322.84374706849\nARIMA(3,2,0): AIC = 57004.334100053165\nARIMA(3,2,1): AIC = 56313.36378912283\nARIMA(3,2,2): AIC = 56316.873642762774\nARIMA(3,2,3): AIC = 56299.528383675766\nARIMA(3,3,0): AIC = 58823.579805310015\nARIMA(3,3,1): AIC = 56999.10341746661\nARIMA(3,3,2): AIC = 56522.91436271143\nARIMA(3,3,3): AIC = 56322.03401094999\nBest model: ARIMA(3, 2, 3) | Best AIC: 56299.528383675766",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "href": "ts_python.html#pronóstico-continuo-rolling-forecast",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Pronóstico Continuo (Rolling Forecast)",
    "text": "Pronóstico Continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\ndef arima_rolling(history: list, test: list, best_order: tuple) -&gt; list:\n    predictions: list = []\n\n    for t in range(len(test)):\n        model: ARIMA = ARIMA(history, order=best_order)\n        model_fit: ARIMAResults = model.fit()\n        output: tuple = model_fit.forecast()\n        yhat: float = output[0]\n        predictions.append(yhat)\n        obs: float = test[t]\n        history.append(obs)\n        print('predicted=%f, expected=%f' % (yhat, obs))\n\n    return predictions\n\ntrain_list: list = train.tolist()\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\ntest7: pd.DataFrame = stock_data.Close[train_size:train_size + 7]\ndates_test7: pd.DataFrame = stock_data.Date[train_size:train_size + 7]\n\ntest7: list = test7.tolist()\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\ntest14: pd.DataFrame = stock_data.Close[train_size:train_size + 14]\ndates_test14: pd.DataFrame = stock_data.Date[train_size:train_size + 14]\n\ntest14: list = test14.tolist()\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\ntest21: pd.DataFrame = stock_data.Close[train_size:train_size + 21]\ndates_test21: pd.DataFrame = stock_data.Date[train_size:train_size + 21]\n\ntest21: list = test21.tolist()\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\ntest28: list = test28.tolist()\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=67576.754117, expected=61912.773438\npredicted=62089.489111, expected=67913.671875\npredicted=67640.534021, expected=65491.390625\npredicted=65614.921428, expected=63778.761719\npredicted=63862.872276, expected=64062.203125\npredicted=64048.241790, expected=67234.171875\npredicted=67079.144700, expected=69958.812500\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=69836.141798, expected=61912.773438\npredicted=62348.038027, expected=67913.671875\npredicted=67479.081772, expected=65491.390625\npredicted=65678.465251, expected=63778.761719\npredicted=63907.858829, expected=64062.203125\npredicted=64040.807348, expected=67234.171875\npredicted=66995.887262, expected=69958.812500\npredicted=69764.380021, expected=69987.835938\npredicted=69985.771853, expected=69455.343750\npredicted=69493.216713, expected=70744.953125\npredicted=70652.888037, expected=69892.828125\npredicted=69953.994254, expected=69645.304688\npredicted=69663.046142, expected=71333.648438\npredicted=71212.356697, expected=69702.148438\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=69821.012635, expected=61912.773438\npredicted=62440.303883, expected=67913.671875\npredicted=67407.913913, expected=65491.390625\npredicted=65706.210355, expected=63778.761719\npredicted=63927.590570, expected=64062.203125\npredicted=64037.546894, expected=67234.171875\npredicted=66959.343112, expected=69958.812500\npredicted=69732.598036, expected=69987.835938\npredicted=69985.433907, expected=69455.343750\npredicted=69499.416842, expected=70744.953125\npredicted=70637.891019, expected=69892.828125\npredicted=69963.880907, expected=69645.304688\npredicted=69665.918496, expected=71333.648438\npredicted=71192.778818, expected=69702.148438\npredicted=69839.828687, expected=65446.972656\npredicted=65794.534708, expected=65980.812500\npredicted=65937.049717, expected=68508.843750\npredicted=68302.905241, expected=67837.640625\npredicted=67892.613800, expected=68896.109375\npredicted=68809.151284, expected=69362.554688\npredicted=69324.336305, expected=71631.359375\n\nARIMA Rolling - Horizonte de 28 días\npredicted=71446.377599, expected=61912.773438\npredicted=62783.665502, expected=67913.671875\npredicted=67267.992172, expected=65491.390625\npredicted=65761.218181, expected=63778.761719\npredicted=63966.615406, expected=64062.203125\npredicted=64031.096722, expected=67234.171875\npredicted=66887.085211, expected=69958.812500\npredicted=69670.065150, expected=69987.835938\npredicted=69984.769007, expected=69455.343750\npredicted=69511.615523, expected=70744.953125\npredicted=70608.373265, expected=69892.828125\npredicted=69983.352161, expected=69645.304688\npredicted=69671.574782, expected=71333.648438\npredicted=71154.216746, expected=69702.148438\npredicted=69876.947391, expected=65446.972656\npredicted=65892.052650, expected=65980.812500\npredicted=65924.903811, expected=68508.843750\npredicted=68245.303688, expected=67837.640625\npredicted=67907.852884, expected=68896.109375\npredicted=68785.141759, expected=69362.554688\npredicted=69313.752922, expected=71631.359375\npredicted=71394.840937, expected=69139.015625\npredicted=69403.275536, expected=70587.882812\npredicted=70432.776270, expected=70060.609375\npredicted=70117.154562, expected=67195.867188\npredicted=67501.553503, expected=63821.472656\npredicted=64169.236849, expected=65738.726562\npredicted=65537.636494, expected=62993.050781\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#auto-arima",
    "href": "ts_python.html#auto-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Auto ARIMA",
    "text": "Auto ARIMA\nTambién tenemos la opción de obtener el modelo ARIMA utilizando una función llamada auto_arima. Sin embargo, esta función genera un simple random walk \\(x_{t} = x_{t - 1} + \\omega_{t}\\), que predice puramente basado en el valor temporal anterior \\(t - 1\\).\n\nauto_arima: pm.arima.auto_arima = pm.arima.auto_arima(\n    train, start_p=1, start_q=1,\n    test='adf',\n    max_p=3, max_q=3,\n    m=1,\n    d=None,\n    seasonal=False,\n    start_P=0, \n    D=0, \n    trace=True,\n    error_action='ignore',  \n    suppress_warnings=True, \n    stepwise=True\n)\n\nPerforming stepwise search to minimize aic\n ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=56337.774, Time=31.17 sec\n ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=56338.937, Time=0.06 sec\n ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=56336.916, Time=0.12 sec\n ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=56337.132, Time=2.78 sec\n ARIMA(0,1,0)(0,0,0)[0]             : AIC=56338.908, Time=0.05 sec\n ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=56336.465, Time=3.15 sec\n ARIMA(3,1,0)(0,0,0)[0] intercept   : AIC=56336.854, Time=4.94 sec\n ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=56336.735, Time=5.70 sec\n ARIMA(3,1,1)(0,0,0)[0] intercept   : AIC=56337.302, Time=57.63 sec\n ARIMA(2,1,0)(0,0,0)[0]             : AIC=56336.468, Time=2.77 sec\n\nBest model:  ARIMA(2,1,0)(0,0,0)[0] intercept\nTotal fit time: 108.451 seconds\n\n\nCon esto, podemos notar que el valor del AIC obtenido es más bajo en el modelo obtenido mediante la función arima_model que en el modelo generado por la función auto_arima. Esta discrepancia se debe a que la función auto_arima se basa únicamente en el dato anterior para realizar predicciones, lo cual no se ajusta adecuadamente al análisis que deseamos realizar. La naturaleza cambiante de los mercados financieros, especialmente en el caso de activos como Bitcoin, que son altamente volátiles, requiere un enfoque más sofisticado que considere la evolución histórica para comprender mejor sus comportamientos.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-ajustado",
    "href": "ts_python.html#modelo-ajustado",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ajustado",
    "text": "Modelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de Akaike. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\ndef fitted_model(train: pd.DataFrame, order: tuple) -&gt; list:\n    model_arima: ARIMA = ARIMA(train, order=order)\n    model_fit: ARIMAResults = model_arima.fit()\n\n    fig: plt.Figure\n    ax: np.ndarray\n\n    plt.rcParams.update({'figure.figsize': (9,9)})\n\n    fig, ax = plt.subplots();\n    plot_predict(model_fit, 1, ax=ax);\n    plt.show();\n\n    return model_arima, model_fit\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\nAÑADIR CONCLUSIÓN DE LAS GRÁFICAS",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#modelo-arima",
    "href": "ts_python.html#modelo-arima",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Modelo ARIMA",
    "text": "Modelo ARIMA\nUtilizaremos el modelo ARIMA a través de la biblioteca statsmodels para explorar diferentes combinaciones de órdenes \\(p, d, q\\). Utilizaremos el método de máxima verosimilitud (method = 'mle') para calcular la verosimilitud exacta mediante el filtro de Kalman.\nComencemos creando una función que tome un dataframe de entrenamiento y devuelva el mejor conjunto de órdenes \\(p, d, q\\) asociados al criterio AIC de bondad de ajuste, junto con los valores de AIC y BIC, y el mejor modelo encontrado.\nRecordemos que, el valor \\(d\\) corresponde al número de diferenciaciones que podemos realizar a nuestra serie de tiempo. Teniendo en cuenta las gráficas de autocorrelación y la prueba de Dickey-Fuller realizada, podemos saber que el máximo valor que puede tomar \\(d\\) será de 1 diferenciación a la serie de tiempo.\n\ndef arima_model(train: pd.DataFrame, criteria: str) -&gt; tuple:\n    best_order: tuple = None\n    best_mdl: ARIMAResults = None\n\n    pq_rng: range = range(2)\n    d_rng: range = range(2)\n\n\n    print(f'Minimizing {criteria.upper} to find best model')\n    print(f'Max value for p, d, q = {max(pq_rng)}')\n\n    if criteria == 'aic':\n        best_aic: float = np.inf\n\n        for p in pq_rng:\n            for d in d_rng:\n                for q in pq_rng:\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_aic: float = tmp_mdl.aic\n                        if tmp_aic &lt; best_aic:\n                            best_aic = tmp_aic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n\n                            print(f'ARIMA{best_order}: AIC = {best_aic}')\n                    except:\n                        continue \n        return best_order, best_aic, best_mdl\n    elif criteria == 'bic':\n        best_bic: float = np.inf\n\n        for p in pq_rng:\n            for d in d_rng:\n                for q in pq_rng:\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_bic: float = tmp_mdl.bic\n                        if tmp_bic &lt; best_bic:\n                            best_bic = tmp_bic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n\n                            print(f'ARIMA{best_order}: BIC = {best_bic}')\n                    except:\n                        continue \n        return best_order, best_bic, best_mdl\n    else:\n        best_hqic: float = np.inf\n\n        for p in pq_rng:\n            for d in d_rng:\n                for q in pq_rng:\n                    try:\n                        tmp_mdl: ARIMAResults = ARIMA(train, order = (p, d, q)).fit()\n                        tmp_hqic: float = tmp_mdl.hqic\n                        if tmp_hqic &lt; best_hqic:\n                            best_hqic = tmp_hqic\n                            best_order = (p, d, q)\n                            best_mdl = tmp_mdl\n\n                            print(f'ARIMA{best_order}: HQIC = {best_hqic}')\n                    except:\n                        continue \n        return best_order, best_hqic, best_mdl\n\nA continuación, evaluemos nuestro conjunto de entrenamiento para obtener el mejor orden, AIC y el mejor modelo ARIMA. Antes de proceder, conviene crear una función que busque el modelo en una ruta especificada y, en caso de existir, lo cargue, o en su defecto, lo guarde si no se encuentra disponible en esa ubicación.\n\ndef get_model(filename: str, train: pd.DataFrame, criteria: str) -&gt; tuple:\n    if os.path.isfile(filename):\n        print(\"Loading model from file...\")\n        with open(filename, 'rb') as f:\n            return pickle.load(f)\n    else:\n        print(\"Model file not found. Running ARIMA model...\")\n        order, c, model = arima_model(train, criteria)\n\n        model_data = (order, c, model)\n        with open(filename, 'wb') as f:\n            pickle.dump(model_data, f)\n\n        return order, c, model\n\n\norder: tuple\naic: float\nmodel: ARIMAResults\n\norder, aic, model = get_model(\"arima_model_aic.pkl\", train, 'aic')\n\nLoading model from file...\n\n\n\n\nBest model: ARIMA(1, 1, 0) | Best AIC: 56337.026464374074",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#residuales-de-los-modelos",
    "href": "ts_python.html#residuales-de-los-modelos",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Residuales de los modelos",
    "text": "Residuales de los modelos\nA continuación, realizaremos las pruebas estadísticas necesarias en el análisis de los residuales. Esto es, realizar test de independencia y normalidad de ellos.",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-bic",
    "href": "ts_python.html#criterio-bic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio BIC",
    "text": "Criterio BIC\n\norder: tuple\nbic: float\nmodel: ARIMAResults\n\norder, bic, model = get_model(\"arima_model_bic.pkl\", train, 'bic')\n\nLoading model from file...\n\n\n\n\nBest model: ARIMA(0, 1, 0) | Best BIC: 56345.06027194312\n\n\n\nModelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de inferencia Bayesiana. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\nAÑADIR CONCLUSIÓN DE LAS GRÁFICAS\n\n\nPronóstico Continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=62993.050781, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=69958.812500, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=69702.148438, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\n\nARIMA Rolling - Horizonte de 28 días\npredicted=71631.359375, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=62993.050781\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo ARIMA sin usar rolling\nRepita el paso 2 ahora sin utilizar rolling. Esto es, realice el pronóstico solo utilizando forecast() para los diferentes horizontes de predicción 7, 14, 21 y 28 días.\nPara realizar el pronóstico sin usar rolling lo único que debemos modificar de nuestra función anterior es eliminar la línea de código donde estamos guardando en el conjunto de datos history el valor observado del test. Es decir, este conjunto en nuestra nueva función ya no variará sino que será estático para cada una de las predicciones realizadas.\n\nprint('ARIMA sin Rolling - Horizonte de 7 días.')\nyhat7_nor: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 14 días.')\nyhat14_nor: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 21 días.')\nyhat21_nor: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 28 días')\nyhat28_nor: list = arima_rolling(train_list, test28, order)\n\nARIMA sin Rolling - Horizonte de 7 días.\npredicted=62993.050781, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\n\nARIMA sin Rolling - Horizonte de 14 días.\npredicted=69958.812500, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\n\nARIMA sin Rolling - Horizonte de 21 días.\npredicted=69702.148438, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\n\nARIMA sin Rolling - Horizonte de 28 días\npredicted=71631.359375, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=62993.050781\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días sin usar rolling\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparación entre modelos\nPara obtener las métricas de los modelos generados usaremos la función forest_accuracy creada anteriormente.\nObtengamos inicialmente las métricas para el modelo usando rolling\n\naccuracy7: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7), \"7 días\")\naccuracy14: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14), \"14 días\")\naccuracy21: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21), \"21 días\")\naccuracy28: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28), \"28 días\")\n\nAhora, obtengamos las métricas para el modelo obtenido sin usar rolling\n\naccuracy7_nor: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7_nor), \"7 días no rolling\")\naccuracy14_nor: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14_nor), \"14 días no rolling\")\naccuracy21_nor: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21_nor), \"21 días no rolling\")\naccuracy28_nor: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28_nor), \"28 días no rolling\")\n\naccuracy: pd.DataFrame = pd.concat([accuracy7, accuracy14, accuracy21, accuracy28, accuracy7_nor, accuracy14_nor, accuracy21_nor, accuracy28_nor])\n\naccuracy\n\n\n\n\n\n\n\n\n\nMAE\nMSE\nMAPE\nRMSE\nR2\n\n\n\n\n7 días\n2485.162388\n9.077674e+06\n0.038625\n3012.917825\n-0.377717\n\n\n14 días\n2188.036830\n9.668759e+06\n0.032680\n3109.462822\n-0.177558\n\n\n21 días\n2007.515253\n7.762696e+06\n0.029841\n2786.161453\n-0.150387\n\n\n28 días\n2123.485073\n8.435359e+06\n0.031312\n2904.368958\n-0.174429\n\n\n7 días no rolling\n2485.162388\n9.077674e+06\n0.038625\n3012.917825\n-0.377717\n\n\n14 días no rolling\n2188.036830\n9.668759e+06\n0.032680\n3109.462822\n-0.177558\n\n\n21 días no rolling\n2007.515253\n7.762696e+06\n0.029841\n2786.161453\n-0.150387\n\n\n28 días no rolling\n2123.485073\n8.435359e+06\n0.031312\n2904.368958\n-0.174429\n\n\n\n\n\n\n\n\nLas métricas obtenidas nos permiten interpretar los resultados de la siguiente forma:\n\nMAE (Error Absoluto Medio): Esta medida representa la media de las diferencias absolutas entre las predicciones y los valores reales. Por ejemplo, un MAE promedio de \\(1827.465\\) indica un error absoluto promedio de \\(1827.465\\) en las predicciones.\nMSE (Error Cuadrático Medio): Es la media de los cuadrados de las diferencias entre las predicciones y los valores reales. Valores altos como \\(4877469\\) indican una dispersión significativa entre las predicciones y los valores reales.\nMAPE (Error Porcentual Absoluto Medio): Esta medida indica el promedio de los errores porcentuales absolutos en relación con los valores reales. Un MAPE promedio de \\(0.0266\\) sugiere que las predicciones tienen un error porcentual promedio del \\(2.6%\\).\nRMSE (Error Cuadrático Medio de la Raíz): Es la raíz cuadrada del MSE y proporciona una medida de la dispersión de los errores en la misma unidad que los datos originales. Un RMSE promedio de \\(2267.960\\) indica que las predicciones se desvían aproximadamente \\(2267.960\\) unidades de los valores reales.\n\\(\\text{R}^2\\) (Coeficiente de Determinación): Es una medida de qué tan bien el modelo se ajusta a los datos reales. Puede interpretarse como la proporción de la varianza total de los datos que es explicada por el modelo. Un valor de \\(\\text{R}^2\\) inferior a \\(0.5\\) (50%) indica un ajuste deficiente del modelo. Además, para los horizontes de predicción mayores a 7 días, los coeficientes de determinación no superan el \\(0.15\\) (15%), lo que sugiere un ajuste insuficiente para períodos de predicción más largos.\n\n\nplt.rcParams.update({'figure.figsize': (9, 12)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(4)\n\nsns.scatterplot(x=test7, y=yhat7, ax=axes[0], color='#5a189a', label='Real vs Estimado')\naxes[0].plot(test7, test7, color='#c77dff', label='Correlación')\naxes[0].set_title('Horizonte 7 días', fontsize=12)\n\nsns.scatterplot(x=test14, y=yhat14, ax=axes[1], color='#5a189a', label='Real vs Estimado')\naxes[1].plot(test14, test14, color='#c77dff', label='Correlación')\naxes[1].set_title('Horizonte 14 días', fontsize=12)\n\nsns.scatterplot(x=test21, y=yhat21, ax=axes[2], color='#5a189a', label='Real vs Estimado')\naxes[2].plot(test21, test21, color='#c77dff', label='Correlación')\naxes[2].set_title('Horizonte 21 días', fontsize=12)\n\nsns.scatterplot(x=test28, y=yhat28, ax=axes[3], color='#5a189a', label='Real vs Estimado')\naxes[3].plot(test28, test28, color='#c77dff', label='Correlación')\naxes[3].set_title('Horizonte 28 días', fontsize=12)\n\nText(0.5, 1.0, 'Horizonte 28 días')",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  },
  {
    "objectID": "ts_python.html#criterio-hqic",
    "href": "ts_python.html#criterio-hqic",
    "title": "Predicciones de Series de Tiempo en Python",
    "section": "Criterio HQIC",
    "text": "Criterio HQIC\n\norder: tuple\nhqic: float\nmodel: ARIMAResults\n\norder, hqic, model = get_model(\"arima_model_hqic.pkl\", train, 'hqic')\n\nLoading model from file...\n\n\n\n\nBest model: ARIMA(0, 1, 0) | Best HQIC: 56341.10486655025\n\n\n\nModelo ajustado\nTeniendo en cuenta lo anterior, para la solución de este problema, consideraremos los mejores órdenes \\(p, d, q\\) según el criterio de inferencia Bayesiana. Estos serán usados como argumento en nuestro modelo ARIMA junto con nuestro conjunto de entrenamiento para obtener el modelo ajustado de interés que utilizaremos para predecir valores futuros mediante el método rolling.\n\nmodel_arima: ARIMA\nmodel_fit: ARIMAResults\n\nmodel_arima, model_fit = fitted_model(train, order)\n\n\n\n\n\n\n\n\nAÑADIR CONCLUSIÓN DE LAS GRÁFICAS\n\n\nPronóstico Continuo (Rolling Forecast)\nAhora procederemos a realizar pronósticos utilizando el método de pronóstico continuo, también conocido como rolling forecasting. Este método utiliza datos históricos para predecir cifras futuras de forma continua a lo largo de un período de tiempo. Si se utiliza eficazmente, este método proporciona previsiones continuas que ayudan a identificar deficiencias de rendimiento, acortar ciclos de planificación y tomar decisiones más informadas para mejorar los resultados. En nuestro caso, implementaremos este enfoque de rolling forecasting utilizando horizontes de 7, 14, 21 y 28 días.\n\nprint('ARIMA Rolling - Horizonte de 7 días.')\nyhat7: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA Rolling - Horizonte de 14 días.')\nyhat14: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA Rolling - Horizonte de 21 días.')\nyhat21: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA Rolling - Horizonte de 28 días')\nyhat28: list = arima_rolling(train_list, test28, order)\n\nARIMA Rolling - Horizonte de 7 días.\npredicted=62993.050781, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\n\nARIMA Rolling - Horizonte de 14 días.\npredicted=69958.812500, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\n\nARIMA Rolling - Horizonte de 21 días.\npredicted=69702.148438, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\n\nARIMA Rolling - Horizonte de 28 días\npredicted=71631.359375, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=62993.050781\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo ARIMA sin usar rolling\nRepita el paso 2 ahora sin utilizar rolling. Esto es, realice el pronóstico solo utilizando forecast() para los diferentes horizontes de predicción 7, 14, 21 y 28 días.\nPara realizar el pronóstico sin usar rolling lo único que debemos modificar de nuestra función anterior es eliminar la línea de código donde estamos guardando en el conjunto de datos history el valor observado del test. Es decir, este conjunto en nuestra nueva función ya no variará sino que será estático para cada una de las predicciones realizadas.\n\nprint('ARIMA sin Rolling - Horizonte de 7 días.')\nyhat7_nor: list  = arima_rolling(train_list, test7, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 14 días.')\nyhat14_nor: list  = arima_rolling(train_list, test14, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 21 días.')\nyhat21_nor: list  = arima_rolling(train_list, test21, order)\n\nprint('\\nARIMA sin Rolling - Horizonte de 28 días')\nyhat28_nor: list = arima_rolling(train_list, test28, order)\n\nARIMA sin Rolling - Horizonte de 7 días.\npredicted=62993.050781, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\n\nARIMA sin Rolling - Horizonte de 14 días.\npredicted=69958.812500, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\n\nARIMA sin Rolling - Horizonte de 21 días.\npredicted=69702.148438, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\n\nARIMA sin Rolling - Horizonte de 28 días\npredicted=71631.359375, expected=61912.773438\npredicted=61912.773438, expected=67913.671875\npredicted=67913.671875, expected=65491.390625\npredicted=65491.390625, expected=63778.761719\npredicted=63778.761719, expected=64062.203125\npredicted=64062.203125, expected=67234.171875\npredicted=67234.171875, expected=69958.812500\npredicted=69958.812500, expected=69987.835938\npredicted=69987.835938, expected=69455.343750\npredicted=69455.343750, expected=70744.953125\npredicted=70744.953125, expected=69892.828125\npredicted=69892.828125, expected=69645.304688\npredicted=69645.304688, expected=71333.648438\npredicted=71333.648438, expected=69702.148438\npredicted=69702.148438, expected=65446.972656\npredicted=65446.972656, expected=65980.812500\npredicted=65980.812500, expected=68508.843750\npredicted=68508.843750, expected=67837.640625\npredicted=67837.640625, expected=68896.109375\npredicted=68896.109375, expected=69362.554688\npredicted=69362.554688, expected=71631.359375\npredicted=71631.359375, expected=69139.015625\npredicted=69139.015625, expected=70587.882812\npredicted=70587.882812, expected=70060.609375\npredicted=70060.609375, expected=67195.867188\npredicted=67195.867188, expected=63821.472656\npredicted=63821.472656, expected=65738.726562\npredicted=65738.726562, expected=62993.050781\n\n\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test7, y=test7, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test7, y=yhat7_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 7 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test14, y=test14, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test14, y=yhat14_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 14 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test21, y=test21, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test21, y=yhat21_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 21 días sin usar rolling\")\nplt.show()\n\nax: np.ndarray = sns.lineplot(x=dates_train[-60:], y=train[-60:], label=\"Train\", color='#5a189a')\nsns.lineplot(x=dates_test28, y=test28, label=\"Test\", color='#7b2cbf')\nsns.lineplot(x=dates_test28, y=yhat28_nor, label=\"Forecast\", color='#c77dff')\n\nplt.title(\"Horizonte de 28 días sin usar rolling\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparación entre modelos\nPara obtener las métricas de los modelos generados usaremos la función forest_accuracy creada anteriormente.\nObtengamos inicialmente las métricas para el modelo usando rolling\n\naccuracy7: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7), \"7 días\")\naccuracy14: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14), \"14 días\")\naccuracy21: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21), \"21 días\")\naccuracy28: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28), \"28 días\")\n\nAhora, obtengamos las métricas para el modelo obtenido sin usar rolling\n\naccuracy7_nor: pd.DataFrame = forecast_accuracy(np.array(test7), np.array(yhat7_nor), \"7 días no rolling\")\naccuracy14_nor: pd.DataFrame = forecast_accuracy(np.array(test14), np.array(yhat14_nor), \"14 días no rolling\")\naccuracy21_nor: pd.DataFrame = forecast_accuracy(np.array(test21), np.array(yhat21_nor), \"21 días no rolling\")\naccuracy28_nor: pd.DataFrame = forecast_accuracy(np.array(test28), np.array(yhat28_nor), \"28 días no rolling\")\n\naccuracy: pd.DataFrame = pd.concat([accuracy7, accuracy14, accuracy21, accuracy28, accuracy7_nor, accuracy14_nor, accuracy21_nor, accuracy28_nor])\n\naccuracy\n\n\n\n\n\n\n\n\n\nMAE\nMSE\nMAPE\nRMSE\nR2\n\n\n\n\n7 días\n2485.162388\n9.077674e+06\n0.038625\n3012.917825\n-0.377717\n\n\n14 días\n2188.036830\n9.668759e+06\n0.032680\n3109.462822\n-0.177558\n\n\n21 días\n2007.515253\n7.762696e+06\n0.029841\n2786.161453\n-0.150387\n\n\n28 días\n2123.485073\n8.435359e+06\n0.031312\n2904.368958\n-0.174429\n\n\n7 días no rolling\n2485.162388\n9.077674e+06\n0.038625\n3012.917825\n-0.377717\n\n\n14 días no rolling\n2188.036830\n9.668759e+06\n0.032680\n3109.462822\n-0.177558\n\n\n21 días no rolling\n2007.515253\n7.762696e+06\n0.029841\n2786.161453\n-0.150387\n\n\n28 días no rolling\n2123.485073\n8.435359e+06\n0.031312\n2904.368958\n-0.174429\n\n\n\n\n\n\n\n\nLas métricas obtenidas nos permiten interpretar los resultados de la siguiente forma:\n\nMAE (Error Absoluto Medio): Esta medida representa la media de las diferencias absolutas entre las predicciones y los valores reales. Por ejemplo, un MAE promedio de \\(1827.465\\) indica un error absoluto promedio de \\(1827.465\\) en las predicciones.\nMSE (Error Cuadrático Medio): Es la media de los cuadrados de las diferencias entre las predicciones y los valores reales. Valores altos como \\(4877469\\) indican una dispersión significativa entre las predicciones y los valores reales.\nMAPE (Error Porcentual Absoluto Medio): Esta medida indica el promedio de los errores porcentuales absolutos en relación con los valores reales. Un MAPE promedio de \\(0.0266\\) sugiere que las predicciones tienen un error porcentual promedio del \\(2.6%\\).\nRMSE (Error Cuadrático Medio de la Raíz): Es la raíz cuadrada del MSE y proporciona una medida de la dispersión de los errores en la misma unidad que los datos originales. Un RMSE promedio de \\(2267.960\\) indica que las predicciones se desvían aproximadamente \\(2267.960\\) unidades de los valores reales.\n\\(\\text{R}^2\\) (Coeficiente de Determinación): Es una medida de qué tan bien el modelo se ajusta a los datos reales. Puede interpretarse como la proporción de la varianza total de los datos que es explicada por el modelo. Un valor de \\(\\text{R}^2\\) inferior a \\(0.5\\) (50%) indica un ajuste deficiente del modelo. Además, para los horizontes de predicción mayores a 7 días, los coeficientes de determinación no superan el \\(0.15\\) (15%), lo que sugiere un ajuste insuficiente para períodos de predicción más largos.\n\n\nplt.rcParams.update({'figure.figsize': (9, 12)})\n\nfig: plt.Figure\naxes: np.ndarray\n\nfig, axes = plt.subplots(4)\n\nsns.scatterplot(x=test7, y=yhat7, ax=axes[0], color='#5a189a', label='Real vs Estimado')\naxes[0].plot(test7, test7, color='#c77dff', label='Correlación')\naxes[0].set_title('Horizonte 7 días', fontsize=12)\n\nsns.scatterplot(x=test14, y=yhat14, ax=axes[1], color='#5a189a', label='Real vs Estimado')\naxes[1].plot(test14, test14, color='#c77dff', label='Correlación')\naxes[1].set_title('Horizonte 14 días', fontsize=12)\n\nsns.scatterplot(x=test21, y=yhat21, ax=axes[2], color='#5a189a', label='Real vs Estimado')\naxes[2].plot(test21, test21, color='#c77dff', label='Correlación')\naxes[2].set_title('Horizonte 21 días', fontsize=12)\n\nsns.scatterplot(x=test28, y=yhat28, ax=axes[3], color='#5a189a', label='Real vs Estimado')\naxes[3].plot(test28, test28, color='#c77dff', label='Correlación')\naxes[3].set_title('Horizonte 28 días', fontsize=12)\n\nText(0.5, 1.0, 'Horizonte 28 días')",
    "crumbs": [
      "Predicción Series de Tiempo - Python",
      "Predicción Series de Tiempo - Python"
    ]
  }
]